# StreamMind 开发文档 v2.0：社交媒体实时舆情监控系统


## **一、技术栈确认

### **核心框架层**
- **主框架**：Spring Boot 3.2.x + Java 17
- **Kafka集成**：Spring for Apache Kafka (`KafkaTemplate`, `@KafkaListener`)
- **流处理**：**直接使用原生 Kafka Streams API**（不引入Spring Cloud Stream抽象）
- **持久化**：Spring Data JPA + **PostgreSQL**（指定学习）
- **实时推送**：Spring WebFlux + WebSocket

### **中间件层**
- **Kafka**：Apache Kafka 3.6.x（Docker单节点）
- **序列化**：JSON Serde（Jackson）
- **AI模型**：Google Gemini 2.5 Flash + 官方Java SDK
- **Prompt设计**：强制JSON Schema输出

### **工具层**
- **构建**：Maven
- **环境**：Docker Compose
- **日志**：SLF4J + Logback
- **前端**：Thymeleaf + Chart.js（最低代码量方案）

---

## **二、微服务架构拆分（4个独立可运行服务）**

### **项目结构**
```text
streammind-v2/
├── collector-service/          # P1+P5：RSSHub采集 + 高并发模拟
├── stream-analyzer/            # P2+P3：Kafka Streams核心处理
├── alert-service/              # P4预警消费 + WebSocket推送
└── docker-compose.yml          # 一键启动所有服务
```

---

## **三、各服务详细开发指南**

### **S1: collector-service（数据采集服务）**

**职责**：从RSSHub抓取多平台数据 + 模拟高并发回放

**核心配置**：
```yaml
# application.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

# RSSHub监控配置（application-dev.yml）
rsshub:
  endpoints:
    - url: https://rsshub.app/weibo/super/hots
      source: weibo
      topic: "#热点话题#"
    - url: https://rsshub.app/zhihu/hotlist
      source: zhihu
      topic: "#知乎热榜#"

# 高并发模拟开关
simulation:
  enabled: true          # 优先用模拟数据快速验证
  replay-speed: 10x      # 1小时数据在6分钟内回放完
  dataset-path: classpath:dataset/weibo-sentiment.csv
```

**核心代码**：
```java
@Component
@RequiredArgsConstructor
public class RssHubCollector {
    private final KafkaTemplate<String, SocialMessage> kafkaTemplate;
    
    @Scheduled(fixedDelay = 100)  // 每100ms抓一次，制造压力
    public void fetchAndSend() {
        // 1. 调用RSSHub REST API
        // 2. 解析为SocialMessage对象
        // 3. 发送：key=topic+source, value=SocialMessage
    }
}

// 消息结构（common模块共享）
public record SocialMessage(
    String messageId,
    String source,          // weibo/zhihu/douyin
    String topic,           // 话题标签
    String userId,
    Long timestamp,
    String content,
    Integer interactionCount // 互动数作为权重
) {}
```

**关键点**：
- **分区策略**：`key = topic + source`，确保同一话题数据进入同一分区，便于Streams聚合
- **模拟优先**：先通过倍速回放历史数据集制造高并发，RSSHub作为补充数据源

---

### **S2: stream-analyzer（流处理核心服务）**

**职责**：独立运行的Kafka Streams应用，无Web层

**核心配置**：
```yaml
spring:
  kafka:
    streams:
      application-id: streammind-analyzer-v2
      bootstrap-servers: localhost:9092
      properties:
        default.key.serde: org.apache.kafka.common.serialization.Serde$StringSerde
        default.value.serde: org.springframework.kafka.support.serializer.JsonSerde
        # 性能调优参数
        num.stream.threads: 4          # 根据CPU核数调整
        cache.max.bytes.buffering: 10485760  # 10MB本地缓存
```

**拓扑实现（P2+P3合并）**：
```java
@Component
public class SentimentAnalysisTopology {
    
    @Bean
    public Topology buildTopology() {
        StreamsBuilder builder = new StreamsBuilder();
        
        // 输入：原始消息流
        KStream<String, SocialMessage> sourceStream = builder.stream("social-messages");
        
        // P2：情感分析（批量异步调用Gemini）
        KStream<String, AnalyzedMessage> analyzedStream = sourceStream
            .process(() -> new BatchAiAnalysisProcessor(), "ai-analysis-processor");
        
        // 输出中间结果
        analyzedStream.to("analyzed-stream");
        
        // P3：时间窗口聚合 + 预警过滤
        KTable<Windowed<String>, TopicStats> statsTable = analyzedStream
            .groupByKey()
            .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(5))
                                   .advanceBy(Duration.ofMinutes(2))) // 滑动窗口
            .aggregate(
                () -> new TopicStats(0, 0, 0.0),
                (key, value, agg) -> agg.update(value),
                Materialized.as("topic-stats-store")
                          .withValueSerde(new JsonSerde<>(TopicStats.class))
            );
        
        // 过滤预警并输出
        statsTable.toStream()
            .filter((windowedKey, stats) -> stats.isAlertWorthy()) // 负面率>70%且评论数>1000
            .mapValues((windowedKey, stats) -> new Alert(
                windowedKey.key(),
                windowedKey.window().endTime(),
                stats.negativeRatio(),
                "【预警】" + windowedKey.key() + " 负面情感达" + String.format("%.2f%%", stats.negativeRatio()*100)
            ))
            .to("alert-events");
        
        return builder.build();
    }
}

// 关键点：BatchAiAnalysisProcessor实现
public class BatchAiAnalysisProcessor implements Processor<String, SocialMessage, String, AnalyzedMessage> {
    private ProcessorContext context;
    private final List<SocialMessage> buffer = new ArrayList<>();
    private static final int BATCH_SIZE = 50;
    
    @Override
    public void process(Record<String, SocialMessage> record) {
        buffer.add(record.value());
        if (buffer.size() >= BATCH_SIZE) {
            flush(); // 批量调用Gemini API
        }
    }
    
    private void flush() {
        // 1. 构建批量Prompt，要求JSON数组输出
        // 2. 调用Gemini 2.5 Flash
        // 3. 解析返回的JSON数组
        // 4. for each结果，调用context.forward()
        buffer.clear();
    }
}
```

**AI Prompt设计（强制JSON输出）**：
```text
请分析以下社交媒体评论的情感，返回严格JSON数组，每个元素包含：
{"messageId": "...", "sentimentScore": 0.85, "sentimentLabel": "Positive", "keywords": ["热点", "吃瓜"]}

评论内容：
1. 这瓜太大了！
2. 真无语，又塌房了...
...
```

---

### **S3: alert-service（预警消费与推送服务）**

**职责**：消费预警Topic + 持久化 + WebSocket实时推送

**核心配置**：
```yaml
spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/streammind
    username: postgres
    password: postgres
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true

kafka:
  consumer:
    group-id: alert-service-group
    topics: alert-events,analyzed-stream  # 消费两个Topic
```

**核心代码**：
```java
@Service
@RequiredArgsConstructor
public class AlertConsumer {
    private final AlertRepository alertRepository;
    private final Sinks.Many<Alert> alertSink; // WebFlux响应式推送
    
    @KafkaListener(topics = "alert-events", groupId = "alert-service-group")
    public void handleAlert(Alert alert) {
        // 1. 持久化到PostgreSQL
        alertRepository.save(alert);
        
        // 2. 推送到WebSocket
        alertSink.tryEmitNext(alert);
        
        // 3. 打印日志（开发调试）
        log.warn("【实时预警】{} - {}", alert.getTopic(), alert.getMessage());
    }
    
    @KafkaListener(topics = "analyzed-stream", groupId = "alert-service-group")
    public void handleAnalyzedResult(AnalyzedMessage msg) {
        // 用于前端实时图表展示的数据
        // 可以缓存到Redis或直接推送到WebSocket
    }
}

@Configuration
public class WebSocketConfig implements WebSocketMessageBrokerConfigurer {
    @Override
    public void registerStompEndpoints(StompEndpointRegistry registry) {
        registry.addEndpoint("/ws-stream").setAllowedOriginPatterns("*").withSockJS();
    }
}
```

**前端页面（Thymeleaf + Chart.js）**：
```html
<!-- src/main/resources/templates/dashboard.html -->
<!DOCTYPE html>
<html xmlns:th="http://www.thymeleaf.org">
<head>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/sockjs-client/dist/sockjs.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/stompjs/lib/stomp.min.js"></script>
</head>
<body>
    <h1>实时舆情监控大屏</h1>
    <canvas id="sentimentChart"></canvas>
    
    <script th:inline="javascript">
        const ctx = document.getElementById('sentimentChart').getContext('2d');
        const chart = new Chart(ctx, {
            type: 'line',
            data: { labels: [], datasets: [{ label: '情感得分', data: [] }] }
        });
        
        const socket = new SockJS('/ws-stream');
        const stomp = Stomp.over(socket);
        stomp.connect({}, function() {
            stomp.subscribe('/topic/alerts', function(alert) {
                // 3行代码实现预警弹窗
                alert(JSON.parse(alert.body).message);
            });
            stomp.subscribe('/topic/sentiment', function(data) {
                // 5行代码实现图表更新
                const point = JSON.parse(data.body);
                chart.data.labels.push(point.topic);
                chart.data.datasets[0].data.push(point.score);
                chart.update('none'); // 无动画更新，降低开销
            });
        });
    </script>
</body>
</html>
```

---

## **四、从P3到1.0闭环：本周行动计划**

### **Day 1-2：完成P4（预警持久化）**
1. **创建`alert-service`模块**，复制P3代码
2. **定义Alert实体**：
   ```java
   @Entity
   public class Alert {
       @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
       private Long id;
       private String topic;
       private LocalDateTime windowEnd;
       private Double negativeRatio;
       private String message;
       private Boolean processed = false; // 标记是否已处理
   }
   ```
3. **实现Repository**：`interface AlertRepository extends JpaRepository<Alert, Long>`
4. **修改P3**：在`filter`后加上`to("alert-events")`，输出到Topic

### **Day 3-4：搭建前端（Thymeleaf + Chart.js）**
1. **在`alert-service`** 添加`spring-boot-starter-thymeleaf`和WebSocket依赖
2. **创建`DashboardController`**：
   ```java
   @Controller
   public class DashboardController {
       @GetMapping("/")
       public String dashboard(Model model) {
           model.addAttribute("alertCount", alertRepository.count());
           return "dashboard"; // 指向src/main/resources/templates/dashboard.html
       }
   }
   ```
3. **复制上面的HTML代码**，确保`Chart.js`和`SockJS`从CDN加载

### **Day 5-6：端到端调试**
1. **启动Docker Compose**：
   ```yaml
   # docker-compose.yml
   version: '3.8'
   services:
     zookeeper:
       image: confluentinc/cp-zookeeper:7.5.0
       environment: { ZOOKEEPER_CLIENT_PORT: 2181 }
     kafka:
       image: confluentinc/cp-kafka:7.5.0
       ports: [ "9092:9092" ]
       environment:
         KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
         KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
     postgres:
       image: postgres:16
       ports: [ "5432:5432" ]
       environment: { POSTGRES_PASSWORD: postgres }
   ```
2. **依次启动**：
   - `collector-service`（先用模拟模式）
   - `stream-analyzer`
   - `alert-service`

3. **验证**：访问`http://localhost:8080`，观察Chart.js图表是否实时更新，PostgreSQL中是否有预警数据

### **Day 7：压测体验**
- 使用`kafka-producer-perf-test.sh`制造10万条消息
- 观察`stream-analyzer`的日志，看背压和延迟情况

---

## **五、1.0到2.0的演进路径（明确里程碑）**

### **版本1.0（当前目标）**
- ✅ **核心目标**：完成P4，实现从采集→分析→聚合→预警→展示的**完整闭环**
- ✅ **数据**：模拟数据为主，RSSHub为辅
- ✅ **部署**：所有服务本地运行，Docker Compose编排
- ✅ **验证**：能够在浏览器看到**实时跳动**的图表和预警弹窗

### **版本1.5（高并发验证）**
- **核心目标**：引入真实高并发场景
- **任务**：
  1. 爬取1万条微博舆情数据，作为回放数据集
  2. 优化`BatchAiAnalysisProcessor`批量大小到100条
  3. 添加Prometheus监控：Kafka Lag、处理延迟、Gemini API响应时间
  4. **压测**：用`k6`脚本模拟100个RSSHub源同时推送

### **版本2.0（微服务化部署）**
- **核心目标**：服务独立部署，可水平扩展
- **任务**：
  1. **容器化**：每个服务写Dockerfile，打包成镜像
  2. **配置中心**：引入Spring Cloud Config（轻量级）
  3. **服务发现**：Nacos（比Eureka轻量，适合学习）
  4. **网关**：Spring Cloud Gateway，统一入口
  5. **扩展`stream-analyzer`**：部署3个实例，验证Kafka分区分配

---

## **六、写在最后：给你的几条建议**

1. **先闭环，再优化**  
   1.0版本不需要完美，只要能看到实时图表在跳动，你的信心就会完全不一样。别在"要不要用Nacos"上纠结，先让服务跑起来。

2. **模拟数据是你的朋友**  
   RSSHub不稳定且频率低，**完全不影响你学习高并发**。用倍速回放历史数据集，你能精确控制并发量，调试更方便。

3. **微服务拆分粒度：够用就行**  
   你现在拆成3个服务已经很好了，别急着上Service Mesh。next step是先把它们各自打包成Docker镜像，能用`docker-compose up -d`一键启动。

4. **监控先行**  
   在2.0版本前，先在`stream-analyzer`里加几个日志：`log.info("Processed batch of {} messages in {}ms", size, duration)`。这比Grafana更直观。

5. **AI成本意识**  
   Gemini 2.5 Flash虽然便宜，但频繁调用也花钱。**批量调用是核心优化点**，也是面试亮点。监控你的API调用次数，学会用`RateLimiter`。

6. **前端够用就好**  
   Thymeleaf+Chart.js足够支撑你展示所有核心指标。等项目有实际用户了，再考虑用Vue重构。

---

```

**记住**：**本周目标只有一个**——打开浏览器能看到Chart.js图表随数据跳动。其他都是次要的。

祝编码愉快！