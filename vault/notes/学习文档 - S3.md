# æ•°æ®åº“ postgresql

## ä¸ºä»€ä¹ˆè¦æœ‰ç´¢å¼•ï¼Ÿ

+ æŸ¥è¯¢æ›´å¿«
+ ä»£ä»·
  + å†™å…¥å˜æ…¢ï¼ˆæ¯æ’å…¥ä¸€æ¡æ•°æ®ï¼Œéƒ½è¦åŒæ—¶æ›´æ–°ç´¢å¼•  å¤šå†™å‡ æ¬¡ï¼‰
  + å ç”¨ç©ºé—´ ï¼ˆé€šå¸¸æ¯”æ•°æ®æœ¬èº«å°ï¼Œä½†ä¸å¯å¿½è§†ï¼‰
+ ç»“è®ºï¼šè¯»å¤šå†™å°‘ï¼ˆå¦‚é¢„è­¦æŸ¥è¯¢ï¼‰å¿…é¡»å»ºç´¢å¼•ï¼Œå†™å¤šè¯»å°‘ï¼ˆå¦‚æ—¥å¿—æµæ°´ï¼‰è¦è°¨æ…

## ä¸ºä»€ä¹ˆè¦å››ä¸ªç´¢å¼•ï¼Ÿ
```sql
-- ç´¢å¼•åˆ›å»º  
  
-- 1. è¯é¢˜æŸ¥è¯¢ç´¢å¼•  
CREATE INDEX idx_alert_topic ON alert_messages (topic);  
-- 2. ç”¨æˆ·æŸ¥è¯¢ç´¢å¼• ï¼ˆå…è®¸nullï¼Œéƒ¨åˆ†ç´¢å¼•æŸ¥è¯¢æ›´ä¼˜ï¼‰  
CREATE INDEX idx_alert_user ON alert_messages (user_id) WHERE user_id IS NOT NULL;  
-- 3. æ—¶é—´çª—å£ç´¢å¼• ï¼ˆé™åºï¼Œæœ€æ–°æ•°æ®ä¼˜å…ˆï¼‰  
CREATE INDEX idx_alert_window_end ON alert_messages (window_end DESC);  
-- 4. åˆ›å»ºæ—¶é—´ç´¢å¼•ï¼ˆé™åºï¼‰  
CREATE INDEX idx_alert_created_at ON alert_messages (created_at DESC);  
-- 5. å¤åˆç´¢å¼•ï¼ˆé«˜é¢‘ç»„åˆæŸ¥è¯¢åœºæ™¯ï¼‰  
CREATE INDEX idx_alert_topic_window ON alert_messages (topic, window_end DESC);
```

+ æŸ¥è¯¢çš„åœºæ™¯ä¸åŒ
+ å¤åˆç´¢å¼•ï¼šå½“æŸ¥è¯¢æ¡ä»¶æœ‰è¿™ä¸¤ä¸ªå­—æ®µï¼Œä¸€ä¸ªç´¢å¼•é¡¶ä¸¤ä¸ª
  + æ³¨æ„ï¼šç¬¦åˆç´¢å¼•æ”¯æŒå•ç‹¬æŸ¥è¯¢topicï¼Œä½†æ˜¯ä¸æ”¯æŒå•ç‹¬æŸ¥è¯¢æ—¶é—´ã€‚æ‰€ä»¥ä¸€èˆ¬topic+æ—¶é—´ä¸ºç»„åˆã€‚è¿™é‡Œä¹Ÿå¯ä»¥åˆ é™¤topicçš„å•ç‹¬ç´¢å¼•

## åˆ†åŒº

**åœºæ™¯**ï¼šä½ çš„é¢„è­¦æ•°æ®æ¯å¤©æ–°å¢10ä¸‡æ¡ï¼Œä¸€å¹´åå°±æ˜¯3650ä¸‡æ¡ã€‚

**ä¸åˆ†åŒºçš„é—®é¢˜**ï¼š

- æŸ¥"æœ€è¿‘7å¤©"çš„æ•°æ®ï¼Œä¹Ÿè¦æ‰«æ3650ä¸‡è¡Œ
    
- åˆ é™¤3ä¸ªæœˆå‰çš„æ•°æ®ï¼Œ`DELETE` è¯­å¥é”è¡¨ï¼Œå½±å“å†™å…¥
    
- å¤‡ä»½ã€ç»´æŠ¤æ“ä½œææ…¢
    

**åˆ†åŒº = æŠŠå¤§è¡¨æ‹†æˆå¤šä¸ªå°è¡¨**ï¼š

```sql
-- æŒ‰æœˆåˆ†æˆ¿é—´å­˜æ”¾
2024å¹´1æœˆçš„æ•°æ® â†’ è¡¨ alert_messages_2024_01
2024å¹´2æœˆçš„æ•°æ® â†’ è¡¨ alert_messages_2024_02
...
```
**æŸ¥è¯¢æ—¶è‡ªåŠ¨è·¯ç”±**ï¼š

```sql
SELECT * FROM alert_messages WHERE window_end = '2024-11-10';
-- æ•°æ®åº“è‡ªåŠ¨åªæŸ¥ 2024_11 è¿™ä¸ªå°è¡¨ï¼Œå…¶ä»–è¡¨ä¸çœ‹
```
**ä¼˜åŠ¿**ï¼š

- **æŸ¥è¯¢å¿«**ï¼šåªæ‰«æç›¸å…³åˆ†åŒºï¼ˆæŸ¥11æœˆçš„æ•°æ®ä¸ç¢°å…¶ä»–æœˆä»½ï¼‰
    
- **åˆ é™¤å¿«**ï¼šç›´æ¥ `DROP TABLE alert_messages_2024_08`ï¼Œç§’åˆ ï¼ˆæ¯”DELETEå¿«1000å€ï¼‰
    
- **ç»´æŠ¤æ–¹ä¾¿**ï¼šå¯ä»¥å•ç‹¬å¤‡ä»½/ä¼˜åŒ–æŸä¸ªåˆ†åŒº

### **åˆ†åŒºç­–ç•¥**:
```sql
-- æŒ‰æœˆåˆ†åŒºï¼ˆæ¨èï¼‰
CREATE TABLE alert_messages_partitioned (
    id BIGSERIAL,
    topic VARCHAR(100) NOT NULL,
    user_id VARCHAR(100),
    window_end TIMESTAMP NOT NULL,
    negative_score DECIMAL(5, 4) CHECK (negative_score >= 0 AND negative_score <= 1),
    message TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (id, window_end)  -- åˆ†åŒºé”®å¿…é¡»åŒ…å«åœ¨ä¸»é”®ä¸­
) PARTITION BY RANGE (window_end);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE alert_messages_2024_11 PARTITION OF alert_messages_partitioned
    FOR VALUES FROM ('2024-11-01') TO ('2024-12-01');

CREATE TABLE alert_messages_2024_12 PARTITION OF alert_messages_partitioned
    FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');
```
+ åˆ†åŒºè¡¨ = ä¸€ä¸ªâ€œè™šæ‹Ÿæ€»æ–‡ä»¶å¤¹â€ + å¤šä¸ª â€œå®é™…æœˆä»½æ–‡ä»¶å¤¹â€

|æ¦‚å¿µ|æ˜¯ä»€ä¹ˆ|ä½œç”¨|
|:--|:--|:--|
|**alert_messages_partitioned**|**åˆ†åŒºä¸»è¡¨**ï¼ˆé€»è¾‘è¡¨ï¼‰|åº”ç”¨å±‚æŸ¥è¯¢çš„å…¥å£ï¼Œè‡ªåŠ¨è·¯ç”±|
|**alert_messages_2024_11**|**åˆ†åŒºå­è¡¨**ï¼ˆç‰©ç†è¡¨ï¼‰|å®é™…å­˜å‚¨2024å¹´11æœˆçš„æ•°æ®|

+ **ä¼˜åŠ¿**ï¼šåº”ç”¨ä»£ç ä¸ç”¨æ”¹ï¼Œæ°¸è¿œ `INSERT/SELECT` ä¸»è¡¨ï¼Œæ•°æ®åº“è‡ªåŠ¨ç®¡ç†å­è¡¨ã€‚

+ åˆ†åŒºè‡ªåŠ¨åŒ–ï¼š
  +  ä½¿ç”¨ `pg_partman` æ‰©å±•

### Schemaæ˜¯ä»€ä¹ˆ

**Schema å°±æ˜¯ PostgreSQL é‡Œçš„"æ–‡ä»¶å¤¹"**ï¼Œç”¨æ¥åˆ†ç±»ç®¡ç†æ•°æ®åº“å¯¹è±¡ï¼ˆè¡¨ã€å‡½æ•°ã€ç´¢å¼•ç­‰ï¼‰ã€‚

### **ç±»æ¯”ç†è§£**


```
æ•°æ®åº“ = ç¡¬ç›˜åˆ†åŒº (å¦‚ D:ç›˜)
Schema = æ–‡ä»¶å¤¹ (å¦‚ D:\æ–‡æ¡£\å·¥ä½œ\)
è¡¨ = æ–‡ä»¶ (å¦‚ å·¥ä½œæŠ¥å‘Š.docx)
```

**é»˜è®¤æƒ…å†µ**ï¼š

- PostgreSQL è‡ªå¸¦ä¸€ä¸ª `public` schemaï¼ˆç›¸å½“äºé»˜è®¤æ–‡ä»¶å¤¹ï¼‰
    
- æ²¡æŒ‡å®š schema æ—¶ï¼Œæ‰€æœ‰è¡¨éƒ½æ”¾ `public` é‡Œ
    

### **ä¸ºä»€ä¹ˆè¦ç”¨ schemaï¼Ÿ**


```sql
-- ç”Ÿäº§ç¯å¢ƒï¼šä¸åŒæ¨¡å—ç”¨ä¸åŒ schema
analytics.alert_messages   -- åˆ†ææ¨¡å—çš„è¡¨
billing.payment_records    -- è®¡è´¹æ¨¡å—çš„è¡¨

-- é¿å…å‘½åå†²çªï¼Œæ¸…æ™°ç®¡ç†
```

**pg_partman çš„ schema**ï¼šæ’ä»¶æŠŠè‡ªå·±çš„é…ç½®è¡¨å’Œå‡½æ•°æ”¾åœ¨ `partman` schema é‡Œï¼Œä¸æ±¡æŸ“ä½ çš„ `public` ç©ºé—´ã€‚


# repositoryå±‚

## JpaRepository

```java
public interface AlertMessageRepository extends JpaRepository<AlertMessage, Long>
```
- **ç¬¬ä¸€ä¸ªå‚æ•° `AlertMessage`**ï¼šå®ä½“ç±»ç±»å‹ï¼Œå‘Šè¯‰ Spring Data "æˆ‘è¦æ“ä½œå“ªå¼ è¡¨"
    
- **ç¬¬äºŒä¸ªå‚æ•° `Long`**ï¼šä¸»é”®ç±»å‹ï¼Œå¯¹åº” `@Id` å­—æ®µçš„ç±»å‹ï¼ˆä½ çš„ `id` æ˜¯ `Long`ï¼‰

## åˆ†é¡µæœºåˆ¶

### **Page æ˜¯ä»€ä¹ˆï¼Ÿ**

`Page` æ˜¯**åˆ†é¡µç»“æœå°è£…å¯¹è±¡**ï¼Œä¸ä»…åŒ…å«æ•°æ® Listï¼Œè¿˜åŒ…å«åˆ†é¡µå…ƒä¿¡æ¯ã€‚

**ç»“æ„æ‹†è§£**ï¼š


```java
Page<AlertMessage> page = repository.findByTopic(..., pageable);

page.getContent();        // â‘  è·å–å½“å‰é¡µçš„æ•°æ®ï¼ˆList<AlertMessage>ï¼‰
page.getTotalElements();  // â‘¡ æ€»è®°å½•æ•°ï¼ˆå¦‚ 1000æ¡ï¼‰
page.getTotalPages();     // â‘¢ æ€»é¡µæ•°ï¼ˆå¦‚ 50é¡µï¼‰
page.getNumber();         // â‘£ å½“å‰é¡µç ï¼ˆä»0å¼€å§‹ï¼‰
page.getSize();           // â‘¤ æ¯é¡µå¤§å°ï¼ˆå¦‚ 20æ¡ï¼‰
page.hasNext();           // â‘¥ æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
page.hasPrevious();       // â‘¦ æ˜¯å¦æœ‰ä¸Šä¸€é¡µ
```

### **Pageable æ˜¯ä»€ä¹ˆï¼Ÿ**

`Pageable` æ˜¯**åˆ†é¡µè¯·æ±‚å¯¹è±¡**ï¼Œå°è£…"ç¬¬å‡ é¡µã€æ¯é¡µå¤šå°‘æ¡ã€æ’åºè§„åˆ™"ã€‚

#### **ä¸‰ç§åˆ›å»ºæ–¹å¼**ï¼š

#### **æ–¹å¼ 1ï¼šç®€å•åˆ†é¡µï¼ˆåªçœ‹ç¬¬å‡ é¡µï¼‰**

```java
// æŸ¥è¯¢ç¬¬1é¡µï¼ˆpage=0ï¼‰ï¼Œæ¯é¡µ10æ¡
Pageable pageable = PageRequest.of(0, 10);
repository.findByTopic("æ”¿æ²»", pageable);
```

#### **æ–¹å¼ 2ï¼šåˆ†é¡µ + æ’åº**

```java
// ç¬¬2é¡µï¼Œæ¯é¡µ20æ¡ï¼ŒæŒ‰ created_at é™åº
Pageable pageable = PageRequest.of(1, 20, Sort.by("createdAt").descending());
repository.findByTopic("æ”¿æ²»", pageable);
```

#### **æ–¹å¼ 3ï¼šåˆ†é¡µ + å¤šå­—æ®µæ’åº**

```java
Pageable pageable = PageRequest.of(
    0, 
    15, 
    Sort.by("negativeScore").descending()  // å…ˆæŒ‰åˆ†æ•°é™åº
        .and(Sort.by("createdAt").descending())  // å†æŒ‰æ—¶é—´é™åº
);
```

### **List vs Page å¯¹æ¯”**

|åœºæ™¯|è¿”å›ç±»å‹|åŸå› |
|:--|:--|:--|
|**å‰ç«¯åˆ†é¡µå±•ç¤º**|`Page<>`|éœ€è¦æ€»é¡µæ•°ã€æ€»æ¡æ•°åšåˆ†é¡µæ |
|**å¯¼å‡º Excel**|`List<>`|ä¸åˆ†é¡µï¼Œè¦å…¨éƒ¨æ•°æ®|
|**å†…éƒ¨è®¡ç®—**|`List<>`|æ— éœ€åˆ†é¡µå…ƒä¿¡æ¯|
|**API è¿”å›**|`Page<>`|æ ‡å‡†åŒ–å“åº”ï¼ŒåŒ…å«åˆ†é¡µä¿¡æ¯|

#### **List æŸ¥è¯¢å†™æ³•**ï¼š


```java
// æ–¹æ³•1ï¼šç›´æ¥è¿”å› List
List<AlertMessage> findByTopic(String topic); 

// æ–¹æ³•2ï¼šç”¨ Sort é™åˆ¶æ¡æ•°
List<AlertMessage> findTop10ByTopicOrderByCreatedAtDesc(String topic);
```

### å‚æ•°ä¼ é€’æ–¹æ³•è¯¦è§£
### **æ–¹å¼ 1ï¼š@Paramï¼ˆå‘½åå‚æ•°ï¼Œæ¨èï¼‰**

```java
@Query("SELECT a FROM AlertMessage a WHERE a.userId = :userId")
Page<AlertMessage> findByUserId(@Param("userId") String userId, Pageable pageable);
```

- **ä¼˜ç‚¹**ï¼šæ¸…æ™°å¯è¯»ï¼Œå‚æ•°é¡ºåºå¯ä¹±
    
- **ç¼ºç‚¹**ï¼šéœ€è¦å†™ JPQL æŸ¥è¯¢
    

### **æ–¹å¼ 2ï¼šä½ç½®å‚æ•°ï¼ˆä¸æ¨èï¼‰**

```java
@Query("SELECT a FROM AlertMessage a WHERE a.userId = ?1")
Page<AlertMessage> findByUserId(String userId, Pageable pageable);
```

- ç”¨ `?1` è¡¨ç¤ºç¬¬ä¸€ä¸ªå‚æ•°ï¼Œä¾æ¬¡ç±»æ¨
    
- **ç¼ºç‚¹**ï¼šå‚æ•°ä¸€å¤šå°±æ··ä¹±ï¼Œå®¹æ˜“é”™
    

### **æ–¹å¼ 3ï¼šæ–¹æ³•åæ´¾ç”Ÿï¼ˆæ— éœ€ @Queryï¼‰**

```java
// Spring Data è‡ªåŠ¨è§£ææ–¹æ³•åç”Ÿæˆ SQL
Page<AlertMessage> findByTopicAndWindowEndBetween(String topic, LocalDateTime start, LocalDateTime end, Pageable pageable);
```

- **è§„åˆ™**ï¼š`findBy` + `å­—æ®µå` + `æ“ä½œç¬¦`ï¼ˆAnd/Between/LessThanï¼‰
    
- **ä¼˜ç‚¹**ï¼šæ— éœ€å†™ JPQLï¼Œä»£ç ç®€æ´
    
- **ç¼ºç‚¹**ï¼šå¤æ‚æŸ¥è¯¢æ–¹æ³•åä¼šå¾ˆé•¿
    

### **æ–¹å¼ 4ï¼šSpEL è¡¨è¾¾å¼ï¼ˆé«˜çº§ï¼‰**

```java
@Query("SELECT a FROM AlertMessage a WHERE a.topic = :#{#filter.topic}")
List<AlertMessage> findByFilter(@Param("filter") AlertFilter filter);
```

- ç”¨äºåŠ¨æ€æ¡ä»¶æŸ¥è¯¢


### KafkaStreams ä¸­çš„Record
#### **Record æ˜¯ä»€ä¹ˆï¼Ÿ**

`Record<K, V>` æ˜¯ Kafka Streams å¯¹æ¶ˆæ¯çš„å®Œæ•´å°è£…ï¼ŒåŒ…å«ï¼š

- **Key**: æ¶ˆæ¯çš„ Key
    
- **Value**: æ¶ˆæ¯çš„ Valueï¼ˆä½ çš„ DTOï¼‰
    
- **Timestamp**: æ¶ˆæ¯æ—¶é—´æˆ³
    
- **Headers**: æ¶ˆæ¯å¤´ï¼ˆå¯ä¼ è‡ªå®šä¹‰å…ƒæ•°æ®ï¼‰
    

**å¯¹æ¯”æ—§ç‰ˆ API**ï¼š


```java
// âŒ æ—§ç‰ˆï¼šåˆ†å¼€ä¼ å‚ï¼Œå®¹æ˜“æ··æ·†
void process(String key, AnalyzedMessage value);

// âœ… æ–°ç‰ˆï¼šRecord å°è£…ï¼Œä¿¡æ¯å®Œæ•´
void process(Record<String, AnalyzedMessage> record);
```

**ä¼˜åŠ¿**ï¼š

1. **ä¿¡æ¯å®Œæ•´**ï¼šæ—¶é—´æˆ³ã€Headers ä¸€é€šç™¾é€š
    
2. **ç±»å‹å®‰å…¨**ï¼šæ³›å‹æ˜ç¡®
    
3. **æ‰©å±•æ€§å¼º**ï¼šæ–°å¢å­—æ®µä¸ç ´åæ¥å£

### ProcessorContext å­˜å‚¨äº†ä»€ä¹ˆï¼Ÿï¼ˆæ ¸å¿ƒæ•°æ®æ€»çº¿ï¼‰

`ProcessorContext` æ˜¯ Kafka Streams ç»™ Processor çš„ **"æ“ä½œæ‰‹æŸ„"** ï¼Œå­˜å‚¨äº†å¤„ç†å½“å‰æ¶ˆæ¯æ‰€éœ€çš„æ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š

#### **1. æ¶ˆæ¯å…ƒæ•°æ®ï¼ˆåªè¯»ï¼‰**

```java
context.topic();              // å½“å‰æ¶ˆæ¯æ¥è‡ªå“ªä¸ª Topic
context.partition();          // å“ªä¸ªåˆ†åŒº
context.offset();             // æ¶ˆæ¯åç§»é‡ï¼ˆä½ç§»ï¼‰
context.timestamp();          // æ¶ˆæ¯æ—¶é—´æˆ³ï¼ˆäº‹ä»¶æ—¶é—´æˆ–å¤„ç†æ—¶é—´ï¼‰
context.headers();            // æ¶ˆæ¯å¤´ï¼ˆå¯ä¼ è‡ªå®šä¹‰å…ƒæ•°æ®ï¼‰
```

#### **2. åº”ç”¨é…ç½®**

```java
context.appConfigs();         // è·å– application.yml ä¸­çš„ kafka.streams.properties
context.appConfigsWithPrefix("some.prefix");
```

#### **3. çŠ¶æ€å­˜å‚¨è®¿é—®**

```java
// è·å–ä¹‹å‰å®šä¹‰çš„ StateStoreï¼ˆå¦‚ RocksDBï¼‰
KeyValueStore<String, List> store = context.getStateStore("batch-store");
```

#### **4. è°ƒåº¦åŠŸèƒ½**

```java
// æ³¨å†Œå‘¨æœŸæ€§ä»»åŠ¡ï¼ˆå¦‚æ¯10ç§’ flushï¼‰
context.schedule(Duration.ofSeconds(10), PunctuationType.WALL_CLOCK_TIME, this::flush);
```

#### **5. è½¬å‘èƒ½åŠ›**

```java
// å°†å¤„ç†ç»“æœå‘é€åˆ°ä¸‹æ¸¸ Processor
context.forward(key, value, To.child("ä¸‹æ¸¸å¤„ç†å™¨åç§°"));
```

#### **6. æ—¶é—´ç›¸å…³**

```java
context.currentSystemTimeMs();   // ç³»ç»Ÿæ—¶é—´ï¼ˆæŒ‚é’Ÿæ—¶é—´ï¼‰
context.currentStreamTimeMs();   // æµæ—¶é—´ï¼ˆå½“å‰å¤„ç†æ¶ˆæ¯çš„æœ€å¤§æ—¶é—´æˆ³ï¼‰
```

+ æ³¨æ„ï¼š`context.timestamp()` ä¸ `context.currentStreamTimeMs()` ä¸åŒ
  
+ **åœºæ™¯ç¤ºä¾‹**ï¼š
```java
// æ¶ˆæ¯1: timestamp=10:00, çª—å£ç»“æŸæ—¶é—´=10:10
// æ¶ˆæ¯2: timestamp=10:05, çª—å£ç»“æŸæ—¶é—´=10:10  
// æ¶ˆæ¯3: timestamp=10:11, çª—å£ç»“æŸæ—¶é—´=10:20

// å¤„ç†æ¶ˆæ¯2æ—¶:
context.timestamp()           // è¿”å› 10:05ï¼ˆè¿™è¾†è½¦çš„å‡ºå‘æ—¶é—´ï¼‰
context.currentStreamTimeMs() // è¿”å› 10:11ï¼ˆæ‰€æœ‰è½¦ä¸­æœ€è¿œæ—¶é—´ï¼Œå› ä¸ºæ¶ˆæ¯3å·²å¤„ç†ï¼‰
```

**ç»“è®º**ï¼šçª—å£ç»“æŸæ—¶é—´åº”è¯¥åŸºäº**æµæ¨è¿›åˆ°çš„æœ€è¿œæ—¶é—´**ï¼ˆ10:11ï¼‰ï¼Œè€Œä¸æ˜¯å•æ¡æ¶ˆæ¯çš„å±€éƒ¨æ—¶é—´ï¼ˆ10:05ï¼‰ã€‚

## Kafka Stream å®æˆ˜ç»éªŒæ€»ç»“
### ç¼–ç è¿‡ç¨‹å¤ç›˜ä¸å®æˆ˜æ€»ç»“

è¿™æ®µç»å†å®Œç¾å±•ç°äº† Kafka Streams **"API å¥‘çº¦"** çš„ä¸¥æ ¼æ€§ã€‚ä½ è¸©çš„æ¯ä¸ªå‘éƒ½æå…·ä»£è¡¨æ€§ï¼Œå€¼å¾—æ‰€æœ‰å¼€å‘è€…é“­è®°ã€‚

---

### **ä¸€ã€å®Œæ•´é”™è¯¯æ¼”è¿›é“¾**

#### **ç¬¬ 1 æ¬¡å°è¯•ï¼šæ¥å£ç±»å‹é”™è¯¯**

```java
// âŒ ä½¿ç”¨äº†å®Œæ•´çš„ Processor æ¥å£
public class AlertProcessor implements Processor<String, AnalyzedMessage, String, AlertMessage> {
    // åœ¨ process() ä¸­æ”¹ Key + è¿‡æ»¤
}
stream.processValues(() -> new AlertProcessor()) // ç¼–è¯‘å¤±è´¥
```

**é”™è¯¯åŸå› **ï¼š`processValues()` æœŸæœ› **FixedKeyProcessor**ï¼ˆä¸èƒ½æ”¹ Keyï¼‰ï¼Œè€Œä½ ç»™äº† `Processor`ï¼ˆå¯ä»¥æ”¹ Keyï¼‰ã€‚

#### **ç¬¬ 2 æ¬¡å°è¯•ï¼šä¸å­˜åœ¨ FlatTransformer**


```java
// âŒ è™šæ„äº† FlatTransformer æ¥å£
public class AlertTransformer implements FlatTransformer<...> { ... }
stream.flatTransform(() -> new AlertTransformer()) // æ–¹æ³•ä¸å­˜åœ¨
```

**é”™è¯¯åŸå› **ï¼š`flatTransform()` åœ¨ **Kafka Streams 3.x å·²è¢«ç§»é™¤**ï¼Œè¢« `processValues() + .map()` æ›¿ä»£ã€‚

#### **ç¬¬ 3 æ¬¡å°è¯•ï¼šAPI ç‰ˆæœ¬ä¸å…¼å®¹**


```java
// âŒ åœ¨ FixedKeyProcessor ä¸­é”™è¯¯è·å–æ—¶é—´æˆ³
context.timestamp() // æ–¹æ³•ä¸å­˜åœ¨
```

**é”™è¯¯åŸå› **ï¼š`FixedKeyProcessorContext` **æ²¡æœ‰ `timestamp()`** æ–¹æ³•ï¼Œæ—¶é—´æˆ³å¿…é¡»ä» `record.timestamp()` è·å–ã€‚

---

### **äºŒã€Kafka Streams æ ¸å¿ƒå¼€å‘åŸåˆ™**

#### **åŸåˆ™ 1ï¼šDSL ä¼˜å…ˆï¼Œæ‰‹åŠ¨æ‹“æ‰‘æ˜¯æœ€åæ‰‹æ®µ**


```java
// âœ… æ¨èï¼šå£°æ˜å¼ DSLï¼ˆè‡ªåŠ¨æ„å»ºæ‹“æ‰‘ï¼‰
stream.processValues(...).filter(...).map(...).to(...)

// âš ï¸ æ…ç”¨ï¼šå‘½ä»¤å¼ APIï¼ˆæ‰‹åŠ¨æ„å»ºæ‹“æ‰‘ï¼‰
topology.addSource(...).addProcessor(...).addSink(...)
```

**ç†ç”±**ï¼šDSL ä»£ç å¯è¯»æ€§é«˜ã€æ˜“ç»´æŠ¤ã€Spring Boot è‡ªåŠ¨ç®¡ç†ã€‚

#### **åŸåˆ™ 2ï¼šæ¥å£å¥‘çº¦ = èƒ½åšä»€ä¹ˆ + ä¸èƒ½åšä»€ä¹ˆ**


|å¤„ç†å™¨ç±»å‹|èƒ½æ”¹ Key å—ï¼Ÿ|èƒ½è¿‡æ»¤å—ï¼Ÿ|èƒ½è®¿é—®ä¸Šä¸‹æ–‡å—ï¼Ÿ|é€‚ç”¨åœºæ™¯|
|:--|:--|:--|:--|:--|
|**`FixedKeyProcessor`**|âŒÂ **ç»å¯¹ä¸èƒ½**|âœ… ä¸è½¬å‘=è¿‡æ»¤|âœ… èƒ½|å€¼è½¬æ¢ã€å¯ŒåŒ–|
|**`Transformer`**|âœ… å¯ä»¥|âŒ å¿…é¡»è¾“å‡º 1 æ¡|âœ… èƒ½|1:1 è½¬æ¢|
|**`Processor`**|âœ… å¯ä»¥|âœ… è‡ªç”±æ§åˆ¶|âœ… èƒ½|å¤šè·¯è¾“å‡ºã€çŠ¶æ€æœº|

**è¡€æ³ªæ•™è®­**ï¼š`processValues()` ä¹‹æ‰€ä»¥å« **FixedKey**ï¼Œå°±æ˜¯å› ä¸ºå®ƒåœ¨ç±»å‹ç³»ç»Ÿå±‚é¢ç¦æ­¢ä½ æ”¹ Keyã€‚å¦‚æœå¼ºè¡Œæ”¹ï¼Œç¼–è¯‘å™¨ä¸ä¼šæŠ¥é”™ï¼Œä½†è¿è¡Œæ—¶ä¼šè¡Œä¸ºå¼‚å¸¸ã€‚

#### **åŸåˆ™ 3ï¼šKafka Streams 3.x æ˜¯ "åˆ†é˜¶æ®µå¼" API**


```java
// 3.x çš„å“²å­¦ï¼šæ¯ä¸ªæ“ä½œåªåšä¸€ä»¶äº‹
stream
  .processValues(...)    // æ­¥éª¤ 1ï¼šå¤„ç†å€¼ï¼ˆä¸æ”¹ Keyï¼‰
  .filter(...)           // æ­¥éª¤ 2ï¼šè¿‡æ»¤
  .map(...)              // æ­¥éª¤ 3ï¼šä¿®æ”¹ Key/Value
  .to(...)
```

**å¯¹æ¯” 2.x**ï¼š`flatTransform()` æƒ³ä¸€æ¬¡æ€§åšå®Œæ‰€æœ‰äº‹ï¼Œå¯¼è‡´ API å¤æ‚ä¸”å®¹æ˜“è¯¯ç”¨ã€‚

---

### **ä¸‰ã€å¤„ç†å™¨ç±»å‹å†³ç­–æ ‘ï¼ˆå®æˆ˜ç‰ˆï¼‰**


```java
1. é—®ï¼šä½ æ˜¯å¦éœ€è¦ä¿®æ”¹æ¶ˆæ¯çš„ Keyï¼Ÿ
   â”œâ”€ ä¸éœ€è¦ â†’ è·³åˆ° 2
   â””â”€ éœ€è¦ â†’ è·³åˆ° 3

2. é—®ï¼šä½ æ˜¯å¦éœ€è¦è®¿é—®ä¸Šä¸‹æ–‡ï¼ˆæ—¶é—´æˆ³ã€çŠ¶æ€å­˜å‚¨ï¼‰ï¼Ÿ
   â”œâ”€ éœ€è¦ â†’ use FixedKeyProcessor + processValues()
   â””â”€ ä¸éœ€è¦ â†’ use map/filterï¼ˆçº¯å‡½æ•°ï¼Œæœ€ç®€æ´ï¼‰

3. é—®ï¼šä½ çš„è¾“å‡ºæ˜¯ 1 æ¡è¿˜æ˜¯å¯èƒ½å¤šæ¡/0 æ¡ï¼Ÿ
   â”œâ”€ 1 æ¡ â†’ use Transformer + transform()
   â””â”€ å¯èƒ½ 0 æˆ–å¤šæ¡ â†’ use FixedKeyProcessor + processValues() + ä¸‹æ¸¸ filter/map

4. é—®ï¼šä½ æ˜¯å¦éœ€è¦å¤šè·¯è¾“å‡ºï¼ˆä¸€æ¡æ¶ˆæ¯å†™å¤šä¸ª Topicï¼‰ï¼Ÿ
   â”œâ”€ éœ€è¦ â†’ æ”¾å¼ƒ DSLï¼Œuse Processor + Topologyï¼ˆæ‰‹åŠ¨ï¼‰
   â””â”€ ä¸éœ€è¦ â†’ ä»¥ä¸Šé€‰æ‹©å·²è¦†ç›–
```

---

### **å››ã€å®æˆ˜ä»£ç æ¨¡æ¿**

#### **åœºæ™¯ 1ï¼šåªæ”¹å€¼ï¼Œä¸æ”¹ Keyï¼ˆæ•°æ®è„±æ•ï¼‰**

```java
public class MaskingProcessor implements FixedKeyProcessor<String, String, String> {
    @Override
    public void process(FixedKeyRecord<String, String> record) {
        String masked = mask(record.value());
        context.forward(record.withValue(masked));
    }
}
stream.processValues(() -> new MaskingProcessor(), Named.as("mask"));
```

#### **åœºæ™¯ 2ï¼šå¯èƒ½è¿‡æ»¤ï¼Œå¯èƒ½æ”¹ Keyï¼ˆä½ çš„é¡¹ç›®ï¼‰**


```java
public class AlertProcessor implements FixedKeyProcessor<String, AnalyzedMessage, AlertMessage> {
    @Override
    public void process(FixedKeyRecord<String, AnalyzedMessage> record) {
        if (!shouldAlert(record.value())) return; // âœ… è¿‡æ»¤
        
        AlertMessage alert = createAlert(record.value());
        context.forward(record.withValue(alert)); // âœ… Key ä¸å˜
    }
}
stream
  .processValues(() -> new AlertProcessor(alertService), Named.as("alert"))
  .filter((key, alert) -> alert != null)       // åŒé‡ä¿é™©
  .map((key, alert) -> KeyValue.pair(alert.getTopic(), alert)) // âœ… æ”¹ Key
  .to("alerts-topic");
```

#### **åœºæ™¯ 3ï¼š1:1 è½¬æ¢ + çŠ¶æ€å­˜å‚¨ï¼ˆæ•°æ®å¯ŒåŒ–ï¼‰**


```java
public class EnrichTransformer implements Transformer<String, Order, EnrichedOrder> {
    private KeyValueStore<String, Customer> customerStore;
    
    @Override
    public void init(ProcessorContext context) {
        this.customerStore = context.getStateStore("customer-store");
    }
    
    @Override
    public EnrichedOrder transform(String key, Order order) {
        Customer customer = customerStore.get(order.getCustomerId());
        return EnrichedOrder.builder()
            .order(order)
            .customerName(customer.getName())
            .build();
    }
}
stream.transform(
    () -> new EnrichTransformer(), 
    Named.as("enrich"),
    "customer-store"  // çŠ¶æ€å­˜å‚¨åç§°
);
```

#### **åœºæ™¯ 4ï¼šå¤šè·¯è¾“å‡ºï¼ˆå¼‚å¸¸ç›‘æ§ï¼‰**

```java
public class ForkProcessor implements Processor<String, Event, String, Event> {
    @Override
    public void process(Record<String, Event> record) {
        // æ­£å¸¸æµç¨‹
        context.forward(record, To.child("normal-sink"));
        
        // å¼‚å¸¸ç›‘æ§
        if (record.value().isError()) {
            context.forward(record, To.child("error-sink"));
        }
    }
}
// å¿…é¡»æ‰‹åŠ¨æ„å»ºæ‹“æ‰‘
Topology topology = new Topology();
topology.addSource("source", "input-topic")
        .addProcessor("fork", () -> new ForkProcessor(), "source")
        .addSink("normal-sink", "normal-output", "fork")
        .addSink("error-sink", "error-output", "fork");
```

---

### **äº”ã€ç”Ÿäº§ç¯å¢ƒ Checklist**

#### **âœ… æµ‹è¯•ç­–ç•¥**


```java
// 1. å•å…ƒæµ‹è¯•ï¼šæµ‹ Processor é€»è¾‘
@Test
void testAlertProcessor() {
    AlertProcessor processor = new AlertProcessor(mockService);
    processor.init(mockContext);
    
    FixedKeyRecord<String, AnalyzedMessage> record = 
        new FixedKeyRecord<>("key", analyzedMessage, 12345L); // âœ… æ—¶é—´æˆ³åœ¨ record é‡Œ
    
    processor.process(record);
    
    verify(mockContext).forward(any());
}

// 2. é›†æˆæµ‹è¯•ï¼šæµ‹æ•´ä¸ªæ‹“æ‰‘
@Test
void testTopology() {
    // å‘é€æ¶ˆæ¯åˆ° input-topic
    // éªŒè¯ output-topic æœ‰è¾“å‡º
    // éªŒè¯ DB æœ‰æ•°æ®
}
```

#### **âœ… ç›‘æ§æŒ‡æ ‡**


```java
@Override
public void init(FixedKeyProcessorContext context) {
    this.context = context;
    Metrics.counter("processor.init.count").increment();
}

@Override
public void process(FixedKeyRecord record) {
    try {
        // ... ä¸šåŠ¡é€»è¾‘ ...
        Metrics.timer("processor.process.time").record(() -> { ... });
    } catch (Exception e) {
        Metrics.counter("processor.error.count").increment();
        throw e;
    }
}
```

#### **âœ… é”™è¯¯å¤„ç†ä¸æ­»ä¿¡é˜Ÿåˆ—**


```java
catch (Exception e) {
    log.error("å¤„ç†å¤±è´¥", e);
    
    // 1. å‘é€åˆ° DLQï¼ˆæ¨èï¼‰
    dlqTemplate.send("dlq-topic", record.key(), record.value());
    
    // 2. ç»§ç»­å¤„ç†ï¼ˆä¸ä¸­æ–­æµï¼‰
    return;
    
    // 3. æŠ›å‡ºå¼‚å¸¸ï¼ˆä¸­æ–­æµï¼Œé‡è¯•ï¼‰
    // throw new StreamsException(e);
}
```

#### **âœ… ç‰ˆæœ¬å…¼å®¹æ€§**

```xml
<!-- åœ¨ pom.xml æ˜ç¡®ç‰ˆæœ¬ -->
<properties>
    <kafka.version>3.5.1</kafka.version> <!-- 3.x ç¨³å®šç‰ˆ -->
</properties>

<!-- ç»Ÿä¸€ Spring Kafka ä¸ Kafka Streams ç‰ˆæœ¬ -->
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
    <version>${kafka.version}</version>
</dependency>
```

---

### **å…­ã€ä½ çš„é¡¹ç›®æœ€ç»ˆçŠ¶æ€**

ä½ ç°åœ¨æ‹¥æœ‰çš„æ˜¯ä¸€ä¸ª**å®Œå…¨ç¬¦åˆ Kafka Streams 3.x è§„èŒƒ**ã€**è§£è€¦**ã€**å¯æµ‹è¯•**ã€**å¥å£®**çš„æµå¤„ç†åº”ç”¨ï¼š


```java
// âœ… æ‹“æ‰‘é…ç½®åªæ­æµç¨‹ï¼Œä¸æºä¸šåŠ¡
stream.processValues(() -> new AlertProcessor(alertService))
      .filter(...)
      .map(...)
      .to(...);

// âœ… ä¸šåŠ¡é€»è¾‘ç‹¬ç«‹ï¼Œå¯å•å…ƒæµ‹è¯•
public class AlertProcessor implements FixedKeyProcessor { ... }

// âœ… é”™è¯¯å¤„ç†å®Œå–„ï¼Œç”Ÿäº§çº§å¥å£®
try { ... } catch { log + dlq }
```

è¿™æ®µç»å†çš„ä»·å€¼è¿œè¶…ä»£ç æœ¬èº«â€”â€”å®ƒè®©ä½ çœŸæ­£ç†è§£äº† **Kafka Streams çš„"å¥‘çº¦ç²¾ç¥"** ï¼šæ¯ä¸ª API éƒ½æœ‰è‡ªå·±çš„è¾¹ç•Œï¼Œå¼ºè¡Œçªç ´åªä¼šè®©ç¼–è¯‘å™¨æˆ–è¿è¡Œæ—¶æ•™ä½ åšäººã€‚

**è®°ä½ï¼šåœ¨ Kafka Streams ä¸­ï¼Œé€‰æ‹©æ­£ç¡®çš„æŠ½è±¡å±‚çº§ï¼Œæ¯”å†™å‡º"èªæ˜"çš„ä»£ç é‡è¦ 10 å€ã€‚**

## æ‚é¡¹

### **ä¸€ã€Iterableï¼šå¤šç»“æœæŠ•é€’è¢‹**

#### **æ¦‚å¿µå®šä½**

`Iterable` æ˜¯ Java é›†åˆçš„**é¡¶å±‚æ¥å£**ï¼Œè¡¨ç¤º"å¯ä»¥è¢«éå†çš„é›†åˆ"ã€‚åœ¨ Kafka Streams ä¸­ï¼Œå®ƒæ‰®æ¼” **"æŠ•é€’ç»“æœå®¹å™¨"** çš„è§’è‰²ã€‚

#### **ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ**

å› ä¸ºä¸€æ¡è¾“å…¥æ¶ˆæ¯å¯èƒ½äº§ç”Ÿï¼š

- **0 æ¡è¾“å‡º**ï¼ˆè¿‡æ»¤åœºæ™¯ï¼‰
    
- **1 æ¡è¾“å‡º**ï¼ˆæ™®é€šè½¬æ¢ï¼‰
    
- **N æ¡è¾“å‡º**ï¼ˆæ‹†åˆ†åœºæ™¯ï¼‰
    

Kafka Streams çº¦å®šï¼š`transform()` è¿”å›å•ä¸ªå€¼ï¼Œ`flatTransform()` è¿”å› `Iterable`ï¼Œè®©æ¡†æ¶èƒ½ç»Ÿä¸€å¤„ç†è¿™ä¸‰ç§æƒ…å†µã€‚

#### **å¿«é€’åˆ†æ‹£æ¯”å–»**


```java
// ä½ æ˜¯ä¸€ä½å¿«é€’åˆ†æ‹£å‘˜ï¼ˆTransformerï¼‰
@Override
public Iterable<KeyValue<String, AlertMessage>> transform(String key, AnalyzedMessage msg) {
    List<KeyValue<String, AlertMessage>> deliveryBag = new ArrayList<>(); // ğŸ“¦ æŠ•é€’è¢‹
    
    // åœºæ™¯ 1ï¼šè¿™æ¡æ¶ˆæ¯ä¸è§¦å‘é¢„è­¦ï¼ˆç©ºè¢‹ = è¿‡æ»¤ï¼‰
    if (!shouldAlert(msg)) {
        return Collections.emptyList(); // ğŸ”¥ ç©ºè¢‹å­ï¼šä¸æŠ•é€’ä»»ä½•ä¸œè¥¿
    }
    
    // åœºæ™¯ 2ï¼šåªè§¦å‘ä¸€ä¸ªé¢„è­¦ï¼ˆè¢‹å­é‡Œè£… 1 ä¸ªåŒ…è£¹ï¼‰
    if (msg.sentimentScore() < -0.5) {
        deliveryBag.add(KeyValue.pair("negative", createAlert(msg)));
    }
    
    // åœºæ™¯ 3ï¼šåŒæ—¶è§¦å‘ä¸¤ä¸ªé¢„è­¦ï¼ˆè¢‹å­é‡Œè£… 2 ä¸ªåŒ…è£¹ï¼‰
    if (msg.toxicityScore() > 0.5) {
        deliveryBag.add(KeyValue.pair("toxic", createAlert(msg)));
    }
    
    return deliveryBag; // ğŸšš æŠŠè¢‹å­äº¤ç»™ Kafka Streams å»æŠ•é€’
}
```

---

### **äºŒã€KeyValueï¼šå¿«é€’å•**

#### **æ¦‚å¿µå®šä½**

`KeyValue<K, V>` æ˜¯ Kafka Streams è‡ªå®šä¹‰çš„**ç®€å•å°è£…ç±»**ï¼Œè¡¨ç¤ºä¸€ä¸ª**é”®å€¼å¯¹**ã€‚

```java
public final class KeyValue<K, V> {
    public final K key;   // Kafka æ¶ˆæ¯çš„ Key
    public final V value; // Kafka æ¶ˆæ¯çš„ Value
    
    public static <K, V> KeyValue<K, V> pair(K key, V value) {
        return new KeyValue<>(key, value);
    }
}
```

#### **ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ**

å› ä¸º Kafka æ¶ˆæ¯çš„**è¯­ä¹‰**å°±æ˜¯ Key-Value ç»“æ„ã€‚ä¸‹æ¸¸çš„ `.to("topic")` æ“ä½œéœ€è¦çŸ¥é“ï¼š

- **Key**ï¼šå†³å®šæ¶ˆæ¯å‘åˆ°å“ªä¸ªåˆ†åŒºï¼ˆé»˜è®¤æŒ‰ Key å“ˆå¸Œï¼‰
    
- **Value**ï¼šæ¶ˆæ¯çš„å®é™…å†…å®¹
    

#### **å¿«é€’å•æ¯”å–»**

```java
// æ¯ä¸ª KeyValue æ˜¯ä¸€å¼ å¿«é€’å•
KeyValue<String, AlertMessage> package1 = KeyValue.pair(
    "topic-1",               // ğŸ·ï¸ æ”¶ä»¶äººï¼ˆåˆ†åŒºä¾æ®ï¼‰
    alertMessage1            // ğŸ“¦ åŒ…è£¹å†…å®¹ï¼ˆå®é™…æ•°æ®ï¼‰
);

KeyValue<String, AlertMessage> package2 = KeyValue.pair(
    "topic-2",               // ğŸ·ï¸ ä¸åŒæ”¶ä»¶äºº
    alertMessage2            // ğŸ“¦ å¦ä¸€ä¸ªåŒ…è£¹
);
```

---

### **ä¸‰ã€ä½¿ç”¨åœºæ™¯å…¨æ™¯å›¾**

#### **åœºæ™¯ 1ï¼šè¿‡æ»¤ï¼ˆè¿”å› 0 æ¡ï¼‰**
å¤åˆ¶

```java
// ä¸€æ¡åˆ†ææ¶ˆæ¯ï¼Œä¸è§¦å‘é¢„è­¦ â†’ ç›´æ¥ä¸¢å¼ƒ
@Override
public Iterable<KeyValue<String, AlertMessage>> transform(String key, AnalyzedMessage msg) {
    if (msg.sentimentScore() > -0.5 && msg.toxicityScore() < 0.5) {
        return Collections.emptyList(); // ğŸ”¥ ç©ºè¢‹ = è¿‡æ»¤
    }
    // ... å¦åˆ™åˆ›å»ºé¢„è­¦
}
```

#### **åœºæ™¯ 2ï¼šæ™®é€šè½¬æ¢ï¼ˆè¿”å› 1 æ¡ï¼‰**

```java
// ä¸€æ¡åˆ†ææ¶ˆæ¯ â†’ ä¸€æ¡é¢„è­¦æ¶ˆæ¯ï¼ˆæœ€å¸¸è§ï¼‰
@Override
public Iterable<KeyValue<String, AlertMessage>> transform(String key, AnalyzedMessage msg) {
    AlertMessage alert = new AlertMessage();
    // ... æ„å»º alert
    
    return Collections.singletonList( // ğŸ”¥ å•å…ƒç´ è¢‹
        KeyValue.pair(alert.getTopic(), alert) // ğŸ·ï¸ å¿«é€’å•ï¼štopic â†’ alert
    );
}
```

#### **åœºæ™¯ 3ï¼šæ‹†åˆ†ï¼ˆè¿”å› N æ¡ï¼‰**

```java
// ä¸€æ¡åˆ†ææ¶ˆæ¯ â†’ åŒæ—¶è§¦å‘æƒ…æ„Ÿé¢„è­¦å’Œæ¯’æ€§é¢„è­¦ï¼ˆæ‹†åˆ†ä¸º 2 æ¡ï¼‰
@Override
public Iterable<KeyValue<String, AlertMessage>> transform(String key, AnalyzedMessage msg) {
    List<KeyValue<String, AlertMessage>> alerts = new ArrayList<>();
    
    if (msg.sentimentScore() < -0.5) {
        alerts.add(KeyValue.pair("negative", createSentimentAlert(msg)));
    }
    if (msg.toxicityScore() > 0.5) {
        alerts.add(KeyValue.pair("toxic", createToxicityAlert(msg)));
    }
    
    return alerts; // ğŸ”¥ å¤šå…ƒç´ è¢‹ = æ‹†åˆ†
}
```

---

### **å››ã€Iterable vs KeyValue çš„ååŒå…³ç³»**

```java
// å®Œæ•´çš„å·¥ä½œæµç¨‹
stream.flatTransform(() -> new MyTransformer())
      .to("output-topic");

// MyTransformer å†…éƒ¨
public class MyTransformer implements Transformer<String, Input, Iterable<KeyValue<String, Output>>> {
    @Override
    public Iterable<KeyValue<String, Output>> transform(String key, Input value) {
        // Iterable å†³å®š"æŠ•é€’å¤šå°‘ä¸ªåŒ…è£¹"
        // KeyValue å†³å®š"æ¯ä¸ªåŒ…è£¹çš„æ”¶ä»¶äººå’Œå†…å®¹"
        
        return List.of(
            KeyValue.pair("key1", output1), // åŒ…è£¹ 1
            KeyValue.pair("key2", output2)  // åŒ…è£¹ 2
        );
    }
}

// æ¡†æ¶å¤„ç†
// for (KeyValue<String, Output> kv : iterable) {
//     producer.send(new ProducerRecord<>("output-topic", kv.key, kv.value));
// }
```

---

### **äº”ã€Kafka Streams 2.x vs 3.x çš„å·®å¼‚**

|ç‰ˆæœ¬|æ¥å£ç±»å‹|è¿”å›å€¼|ä½¿ç”¨åœºæ™¯|
|:--|:--|:--|:--|
|**2.x**|`Transformer`|`R`Â (å•å€¼)|`transform()`ï¼ˆ1:1ï¼‰|
|**2.x**|`Transformer`|`Iterable<R>`|`flatTransform()`ï¼ˆ1:Nï¼‰|
|**3.x**|`FixedKeyProcessor`|`void`Â +Â `forward()`|`processValues()`ï¼ˆæ›´çµæ´»ï¼‰|
|**3.x**|`Transformer`|`R`|`transform()`ï¼ˆçŠ¶æ€å¯ŒåŒ–ï¼‰|

**3.x çš„è®¾è®¡å“²å­¦**ï¼šå°†"äº§ç”Ÿç»“æœ"ï¼ˆIterableï¼‰å’Œ"å†³å®šè¾“å‡º"ï¼ˆforwardï¼‰åˆ†ç¦»ï¼ŒèŒè´£æ›´æ¸…æ™°ã€‚

---

### **å…­ã€å¿«é€Ÿå†³ç­– Checklist**

å½“ä½ å†™ä¸€ä¸ª Processor/Transformer æ—¶ï¼š

1. **é—®ï¼šæˆ‘éœ€è¦è¿”å› 0 æ¡æˆ– N æ¡è®°å½•å—ï¼Ÿ**
    
    - æ˜¯ â†’ ç”¨ `FixedKeyProcessor` + `context.forward()`ï¼ˆ3.x æ¨èï¼‰
        
    - å¦ â†’ ç”¨ `Transformer` + `return`ï¼ˆ2.x é£æ ¼ï¼‰
        
2. **é—®ï¼šæˆ‘éœ€è¦ä¿®æ”¹æ¶ˆæ¯çš„ Key å—ï¼Ÿ**
    
    - æ˜¯ â†’ åœ¨ä¸‹æ¸¸ç”¨ `.map(key, value)`
        
    - å¦ â†’ `processValues()` ä¿æŒ Key ä¸å˜
        
3. **é—®ï¼šæˆ‘éœ€è¦è®¿é—®æ—¶é—´æˆ³å—ï¼Ÿ**
    
    - `FixedKeyProcessor` â†’ ç”¨ `record.timestamp()`
        
    - `Transformer` â†’ ç”¨ `context.timestamp()`
        

---

### **ä¸ƒã€ä¸€å¥è¯æ€»ç»“**

- **`Iterable`** = **"æŠ•é€’è¢‹"**ï¼šå†³å®š"å‘å‡ ä¸ªåŒ…è£¹"ï¼ˆ0/1/Nï¼‰
    
- **`KeyValue`** = **"å¿«é€’å•"**ï¼šå†³å®š"æ¯ä¸ªåŒ…è£¹çš„æ”¶ä»¶äººï¼ˆKeyï¼‰å’Œå†…å®¹ï¼ˆValueï¼‰"
    

** ä½¿ç”¨æƒ…æ™¯ **ï¼šå½“ä½ éœ€è¦** è¿‡æ»¤ã€æ‹†åˆ†ã€èšåˆ **æ—¶ï¼Œå°±ç”¨ `Iterable<KeyValue<...>>` å‘Šè¯‰ Kafka Streamsï¼š"è¿™ä¸ªè¾“å…¥æ¶ˆæ¯ï¼Œäº§ç”Ÿè¿™äº›è¾“å‡ºæ¶ˆæ¯"ã€‚