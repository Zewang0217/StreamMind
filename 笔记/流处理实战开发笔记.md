# æµå¤„ç†å®æˆ˜å¼€å‘ç¬”è®° ğŸ“Š

## ğŸ¯ é›¶åŸºç¡€å…¥é—¨æŒ‡å—

### ä»€ä¹ˆæ˜¯æµå¤„ç†ï¼Ÿ
æµå¤„ç†å°±æ˜¯**å®æ—¶å¤„ç†è¿ç»­ä¸æ–­çš„æ•°æ®æµ**ï¼Œå°±åƒæ°´ç®¡é‡Œçš„æ°´ä¸€æ ·ï¼Œæ•°æ®æºæºä¸æ–­åœ°æµè¿›æ¥ï¼Œæˆ‘ä»¬è¾¹æ¥æ”¶è¾¹å¤„ç†ï¼Œè€Œä¸æ˜¯ç­‰æ‰€æœ‰æ•°æ®éƒ½åˆ°é½å†å¤„ç†ã€‚

**ç”Ÿæ´»ä¸­çš„ä¾‹å­ï¼š**
- å¾®åšå®æ—¶çƒ­æœï¼šæ¯æ¡å¾®åšå‘å‡ºæ¥å°±ç«‹å³åˆ†æçƒ­åº¦
- è‚¡ç¥¨äº¤æ˜“ç³»ç»Ÿï¼šè‚¡ä»·æ¯å˜åŠ¨ä¸€æ¬¡å°±ç«‹å³å¤„ç†äº¤æ˜“
- æ™ºèƒ½å®¢æœï¼šç”¨æˆ·æ¯å‘ä¸€æ¡æ¶ˆæ¯å°±ç«‹å³åˆ†ææ„å›¾å¹¶å›å¤

### æ ¸å¿ƒæ¦‚å¿µç†è§£

```
æ•°æ®æº â†’ Kafkaæ¶ˆæ¯é˜Ÿåˆ— â†’ æµå¤„ç†ç¨‹åº â†’ ç»“æœè¾“å‡º
   â†“           â†“            â†“          â†“
å¾®åšæ•°æ®  â†’  social-messages â†’ æƒ…æ„Ÿåˆ†æ â†’ é¢„è­¦/å±•ç¤º
```

## ğŸ—ï¸ é¡¹ç›®æ¶æ„æ¼”è¿›

### ç¬¬ä¸€é˜¶æ®µï¼šç®€å•ä¸‰å±‚æ¶æ„
```
Producer(ç”Ÿäº§) â†’ Kafka â†’ Consumer(æ¶ˆè´¹)
```

### ç¬¬äºŒé˜¶æ®µï¼šä¸“ä¸šæµå¤„ç†æ¶æ„ï¼ˆå½“å‰ï¼‰
```
Collector(æ•°æ®é‡‡é›†) â†’ Kafka â†’ Stream-Analyzer(æµåˆ†æ) â†’ Kafka â†’ Alert-Service(é¢„è­¦)
```

### å„æ¨¡å—èŒè´£

| æ¨¡å— | èŒè´£ | ç±»æ¯” |
|-----|------|------|
| **Collector** | è¯»å–æ•°æ®ï¼Œå‘é€åˆ°Kafka | æ•°æ®æ”¶é›†å‘˜ |
| **Stream-Analyzer** | å®æ—¶åˆ†ææ•°æ®æµ | æ•°æ®åˆ†æå¸ˆ |
| **Alert-Service** | æ ¹æ®åˆ†æç»“æœé¢„è­¦ | é¢„è­¦ç³»ç»Ÿ |
| **Common** | å…±äº«æ•°æ®ç»“æ„ | é€šç”¨å·¥å…·ç®± |

## ğŸ”§ å¼€å‘ç¯å¢ƒå‡†å¤‡

### 1. åŸºç¡€ç¯å¢ƒ
```bash
# Java 17+ (å¿…é¡»ä½¿ç”¨17æˆ–æ›´é«˜ç‰ˆæœ¬)
java -version

# Maven 3.6+
mvn -version

# Docker (è¿è¡ŒKafka)
docker --version
```

### 2. å¯åŠ¨Kafkaï¼ˆä½¿ç”¨Dockerï¼‰
```bash
# åœ¨ä½ çš„é¡¹ç›®ç›®å½•ä¸‹
docker-compose up -d

# æ£€æŸ¥æ˜¯å¦å¯åŠ¨æˆåŠŸ
docker ps
```

### 3. åˆ›å»ºSpring Booté¡¹ç›®
ä½¿ç”¨ Spring Initializr (https://start.spring.io/)
- Project: Maven
- Language: Java
- Spring Boot: 3.3.6
- Java: 17
- Dependencies: Spring Web, Spring for Apache Kafka

## ğŸ“¦ Commonæ¨¡å—å¼€å‘ï¼ˆæ•°æ®å®šä¹‰ï¼‰

### ç¬¬ä¸€æ­¥ï¼šå®šä¹‰æ¶ˆæ¯ç»“æ„
```java
// SocialMessage.java - åŸå§‹ç¤¾äº¤æ¶ˆæ¯
@Builder  // å»ºé€ è€…æ¨¡å¼ï¼Œæ–¹ä¾¿åˆ›å»ºå¯¹è±¡
public record SocialMessage (
    String messageId,    // æ¶ˆæ¯IDï¼Œå…¨å±€å”¯ä¸€
    String source,       // æ¥æºï¼šweibo, zhihuç­‰
    String topic,        // ä¸»é¢˜
    String userId,       // ç”¨æˆ·ID
    LocalDateTime timestamp,  // æ—¶é—´æˆ³
    String content,      // å†…å®¹
    int interactionCount // äº’åŠ¨æ•°ï¼šç‚¹èµã€è½¬å‘ç­‰
) {}
```

### ç¬¬äºŒæ­¥ï¼šå®šä¹‰åˆ†æç»“æœç»“æ„
```java
// AnalyzedMessage.java - åˆ†æåçš„æ¶ˆæ¯
@Builder
public record AnalyzedMessage (
    String messageId,
    String source,
    String topic, 
    String userId,
    LocalDateTime timestamp,
    String content,
    int interactionCount,
    double sentimentScore,    // æƒ…æ„Ÿåˆ†æ•°ï¼š-1.0(è´Ÿé¢) ~ 1.0(æ­£é¢)
    String sentimentLabel,    // æƒ…æ„Ÿæ ‡ç­¾ï¼šPositive, Negative, Neutral
    double toxicityScore      // æ¯’æ€§åˆ†æ•°ï¼š0.0(å®‰å…¨) ~ 1.0(æœ‰æ¯’)
) {}
```

### ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰Kafkaå¸¸é‡
```java
// KafkaConstants.java - æ‰€æœ‰Kafkaç›¸å…³çš„å¸¸é‡
public class KafkaConstants {
    // ä¸»é¢˜åç§°
    public static final String SOCIAL_MESSAGES_TOPIC = "social-messages";
    public static final String ANALYZED_STREAM_TOPIC = "analyzed-stream";
    public static final String ALERT_EVENTS_TOPIC = "alert-events";
    
    // åºåˆ—åŒ–é…ç½®
    public static final String JSON_SERIALIZER = "org.springframework.kafka.support.serializer.JsonSerializer";
    public static final String JSON_DESERIALIZER = "org.springframework.kafka.support.serializer.JsonDeserializer";
}
```

## ğŸ“¥ Collector-Serviceå¼€å‘ï¼ˆæ•°æ®é‡‡é›†ï¼‰

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºä¸»ç±»
```java
@SpringBootApplication
@EnableScheduling  // å¯ç”¨å®šæ—¶ä»»åŠ¡
public class CollectorServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(CollectorServiceApplication.class, args);
    }
}
```

### ç¬¬äºŒæ­¥ï¼šå®ç°æ•°æ®æ”¶é›†å™¨
```java
@Component
@Slf4j  // æ—¥å¿—æ³¨è§£
@RequiredArgsConstructor  // è‡ªåŠ¨ç”Ÿæˆæ„é€ å‡½æ•°
public class SimulationCollector {
    
    private final KafkaTemplate<String, SocialMessage> kafkaTemplate;
    private List<SocialMessageCsvDto> csvData;  // CSVæ•°æ®ç¼“å­˜
    private int currentIndex = 0;  // å½“å‰è¯»å–ä½ç½®
    
    // é¡¹ç›®å¯åŠ¨æ—¶åŠ è½½CSVæ•°æ®
    @PostConstruct
    public void loadCsvData() throws Exception {
        // è¯»å–CSVæ–‡ä»¶
        var resource = new ClassPathResource("csv/sample-data.csv");
        try (var reader = new InputStreamReader(resource.getInputStream())) {
            csvData = new CsvToBeanBuilder<SocialMessageCsvDto>(reader)
                .withType(SocialMessageCsvDto.class)
                .build()
                .parse();
        }
        log.info("åŠ è½½äº† {} æ¡CSVæ•°æ®", csvData.size());
    }
    
    // æ¯10æ¯«ç§’å‘é€10æ¡æ¶ˆæ¯
    @Scheduled(fixedDelay = 10)
    public void sendBatchMessages() {
        if (csvData == null || csvData.isEmpty()) return;
        
        for (int i = 0; i < 10; i++) {
            // å¾ªç¯ä½¿ç”¨æ•°æ®
            if (currentIndex >= csvData.size()) {
                currentIndex = 0;
            }
            
            SocialMessageCsvDto dto = csvData.get(currentIndex++);
            
            // æ„å»ºæ¶ˆæ¯å¯¹è±¡
            SocialMessage message = SocialMessage.builder()
                .messageId(UUID.randomUUID().toString())
                .source(random.nextBoolean() ? "weibo" : "zhihu")
                .topic(dto.getTopic())
                .userId(dto.getUserId())
                .timestamp(LocalDateTime.now())
                .content(dto.getContent())
                .interactionCount(Integer.parseInt(dto.getInteractionCount()))
                .build();
            
            // å‘é€åˆ°Kafka
            kafkaTemplate.send(KafkaConstants.SOCIAL_MESSAGES_TOPIC, 
                             message.messageId(), message);
            log.info("å‘é€æ¶ˆæ¯: {}", message);
        }
    }
}
```

### ç¬¬ä¸‰æ­¥ï¼šé…ç½®Kafka
```java
@Configuration
public class KafkaConfig {
    
    @Bean
    public ProducerFactory<String, SocialMessage> producerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        
        // æ€§èƒ½ä¼˜åŒ–é…ç½®
        config.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);  // æ‰¹å¤„ç†å¤§å°
        config.put(ProducerConfig.LINGER_MS_CONFIG, 10);      // å»¶è¿Ÿå‘é€ç­‰å¾…æ—¶é—´
        config.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "gzip");  // å‹ç¼©
        
        return new DefaultKafkaProducerFactory<>(config);
    }
    
    @Bean
    public KafkaTemplate<String, SocialMessage> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

## âš¡ Stream-Analyzerå¼€å‘ï¼ˆæµå¤„ç†æ ¸å¿ƒï¼‰

### ç¬¬ä¸€æ­¥ï¼šç†è§£Kafka Streams
Kafka Streamså°±åƒä¸€æ¡**æ•°æ®ç”Ÿäº§çº¿**ï¼Œæ•°æ®ä»ä¸€ç«¯è¿›å»ï¼Œç»è¿‡å„ç§å¤„ç†ï¼Œä»å¦ä¸€ç«¯å‡ºæ¥ã€‚

```
è¾“å…¥ä¸»é¢˜ â†’ å¤„ç†é€»è¾‘ â†’ è¾“å‡ºä¸»é¢˜
social-messages â†’ æƒ…æ„Ÿåˆ†æ â†’ analyzed-stream
```

### ç¬¬äºŒæ­¥ï¼šåˆ›å»ºæµå¤„ç†é…ç½®
```java
@Configuration
@EnableKafkaStreams
public class KafkaStreamConfig {
    
    @Bean
    public KafkaStreamsConfiguration kafkaStreamsConfig() {
        Map<String, Object> props = new HashMap<>();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "stream-analyzer");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, JsonSerde.class);
        
        return new KafkaStreamsConfiguration(props);
    }
    
    @Bean
    public KStream<String, SocialMessage> kStream(StreamsBuilder streamsBuilder) {
        // åˆ›å»ºæµå¤„ç†æ‹“æ‰‘
        KStream<String, SocialMessage> inputStream = streamsBuilder
            .stream(KafkaConstants.SOCIAL_MESSAGES_TOPIC);
        
        // å¤„ç†é€»è¾‘ï¼šè°ƒç”¨AIæœåŠ¡åˆ†æ
        KStream<String, AnalyzedMessage> analyzedStream = inputStream
            .mapValues(this::analyzeMessage);
        
        // è¾“å‡ºåˆ°ç›®æ ‡ä¸»é¢˜
        analyzedStream.to(KafkaConstants.ANALYZED_STREAM_TOPIC);
        
        return inputStream;
    }
    
    private AnalyzedMessage analyzeMessage(SocialMessage message) {
        // è¿™é‡Œè°ƒç”¨AIæœåŠ¡è¿›è¡Œåˆ†æ
        // ç°åœ¨å…ˆç”¨æ¨¡æ‹Ÿæ•°æ®
        double sentimentScore = Math.random() * 2 - 1;  // -1åˆ°1
        String sentimentLabel = sentimentScore > 0.3 ? "Positive" : 
                               sentimentScore < -0.3 ? "Negative" : "Neutral";
        double toxicityScore = Math.random() * 0.3;     // 0åˆ°0.3
        
        return AnalyzedMessage.builder()
            .messageId(message.messageId())
            .source(message.source())
            .topic(message.topic())
            .userId(message.userId())
            .timestamp(message.timestamp())
            .content(message.content())
            .interactionCount(message.interactionCount())
            .sentimentScore(sentimentScore)
            .sentimentLabel(sentimentLabel)
            .toxicityScore(toxicityScore)
            .build();
    }
}
```

### ç¬¬ä¸‰æ­¥ï¼šé«˜çº§æµå¤„ç† - æ‰¹é‡AIåˆ†æ
```java
// BatchAIAnalysisProcessor.java - æ‰¹é‡å¤„ç†ä¼˜åŒ–
public class BatchAIAnalysisProcessor implements 
    Processor<String, SocialMessage, String, AnalyzedMessage> {
    
    private static final int BATCH_SIZE = 50;           // æ‰¹å¤„ç†å¤§å°
    private static final Duration FLUSH_INTERVAL = Duration.ofSeconds(10);  // åˆ·æ–°é—´éš”
    
    private List<SocialMessage> buffer;  // æ¶ˆæ¯ç¼“å†²åŒº
    private MockAIService aiService;     // AIæœåŠ¡
    
    @Override
    public void init(ProcessorContext context) {
        this.context = context;
        this.buffer = new ArrayList<>(BATCH_SIZE);
        
        // è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼šæ¯1ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦åˆ·æ–°
        context.schedule(Duration.ofMillis(1000), 
                        PunctuationType.WALL_CLOCK_TIME, 
                        this::flush);
    }
    
    @Override
    public void process(Record<String, SocialMessage> record) {
        SocialMessage message = record.value();
        
        // è¿‡æ»¤ç©ºæ¶ˆæ¯
        if (message.content() == null || message.content().isEmpty()) {
            return;
        }
        
        // æ·»åŠ åˆ°ç¼“å†²åŒº
        buffer.add(message);
        
        // è¾¾åˆ°æ‰¹å¤„ç†å¤§å°å°±ç«‹å³å¤„ç†
        if (buffer.size() >= BATCH_SIZE) {
            flush();
        }
    }
    
    // åˆ·æ–°å¤„ç†ç¼“å†²åŒºä¸­çš„æ¶ˆæ¯
    private void flush() {
        if (buffer.isEmpty()) return;
        
        try {
            // æ‰¹é‡è°ƒç”¨AIæœåŠ¡
            List<AnalyzedMessage> results = aiService.analyzeBatch(buffer);
            
            // å‘é€å¤„ç†ç»“æœ
            for (AnalyzedMessage result : results) {
                context.forward(new Record<>(result.topic(), result, 
                                           context.currentStreamTimeMs()));
            }
        } catch (Exception e) {
            log.error("AIåˆ†æå¤±è´¥: {}", e.getMessage());
            // é™çº§å¤„ç†ï¼šå‘é€åŸå§‹æ¶ˆæ¯ï¼ˆæ ‡è®°ä¸ºåˆ†æå¤±è´¥ï¼‰
            for (SocialMessage message : buffer) {
                AnalyzedMessage fallback = createFallbackAnalysis(message);
                context.forward(new Record<>(fallback.topic(), fallback, 
                                           context.currentStreamTimeMs()));
            }
        } finally {
            buffer.clear();  // æ¸…ç©ºç¼“å†²åŒº
        }
    }
    
    // åˆ›å»ºé™çº§åˆ†æç»“æœ
    private AnalyzedMessage createFallbackAnalysis(SocialMessage message) {
        return AnalyzedMessage.builder()
            .messageId(message.messageId())
            .source(message.source())
            .topic(message.topic())
            .userId(message.userId())
            .timestamp(message.timestamp())
            .content(message.content())
            .interactionCount(message.interactionCount())
            .sentimentScore(0.0)      // ä¸­æ€§åˆ†æ•°
            .sentimentLabel("Neutral")
            .toxicityScore(0.0)       // å®‰å…¨åˆ†æ•°
            .build();
    }
}
```

## ğŸš¨ Alert-Serviceå¼€å‘ï¼ˆé¢„è­¦ç³»ç»Ÿï¼‰

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºé¢„è­¦ç›‘å¬å™¨
```java
@Component
@Slf4j
public class AlertProcessor {
    
    private final KafkaTemplate<String, Alert> kafkaTemplate;
    
    // ç›‘å¬åˆ†æç»“æœ
    @KafkaListener(topics = KafkaConstants.ANALYZED_STREAM_TOPIC, 
                   groupId = "alert-service-group")
    public void processAnalyzedMessage(AnalyzedMessage message) {
        log.info("æ”¶åˆ°åˆ†ææ¶ˆæ¯: sentiment={}, toxicity={}", 
                message.sentimentScore(), message.toxicityScore());
        
        // æƒ…æ„Ÿé¢„è­¦åˆ¤æ–­
        if (message.sentimentScore() < -0.5) {
            sendAlert("NEGATIVE_SENTIMENT", message, 
                     String.format("ç”¨æˆ· %s å‘è¡¨è´Ÿé¢å†…å®¹", message.userId()));
        }
        
        // æ¯’æ€§é¢„è­¦åˆ¤æ–­
        if (message.toxicityScore() > 0.7) {
            sendAlert("HIGH_TOXICITY", message,
                     String.format("ç”¨æˆ· %s å‘è¡¨é«˜æ¯’æ€§å†…å®¹", message.userId()));
        }
        
        // å¯ä»¥æ·»åŠ æ›´å¤šé¢„è­¦è§„åˆ™
        checkForSpam(message);      // åƒåœ¾ä¿¡æ¯æ£€æµ‹
        checkForSensitive(message); // æ•æ„Ÿå†…å®¹æ£€æµ‹
    }
    
    private void sendAlert(String alertType, AnalyzedMessage message, String description) {
        Alert alert = Alert.builder()
            .alertId(UUID.randomUUID().toString())
            .messageId(message.messageId())
            .userId(message.userId())
            .alertType(alertType)
            .severity(calculateSeverity(message, alertType))
            .description(description)
            .timestamp(LocalDateTime.now())
            .build();
        
        // å‘é€é¢„è­¦åˆ°Kafka
        kafkaTemplate.send(KafkaConstants.ALERT_EVENTS_TOPIC, alert);
        log.warn("ç”Ÿæˆé¢„è­¦: {}", alert);
    }
    
    private String calculateSeverity(AnalyzedMessage message, String alertType) {
        return switch (alertType) {
            case "NEGATIVE_SENTIMENT" -> 
                message.sentimentScore() < -0.8 ? "HIGH" : "MEDIUM";
            case "HIGH_TOXICITY" -> 
                message.toxicityScore() > 0.9 ? "HIGH" : "MEDIUM";
            default -> "LOW";
        };
    }
}
```

### ç¬¬äºŒæ­¥ï¼šé¢„è­¦æŒä¹…åŒ–
```java
@Entity
@Table(name = "alerts")
public class AlertRecord {
    @Id
    private String alertId;
    private String messageId;
    private String userId;
    private String alertType;
    private String severity;
    private String description;
    private LocalDateTime timestamp;
    private boolean processed;  // æ˜¯å¦å·²å¤„ç†
    private LocalDateTime processedTime;
}

@Service
public class AlertStorageService {
    
    @KafkaListener(topics = KafkaConstants.ALERT_EVENTS_TOPIC,
                   groupId = "alert-storage-group")
    public void storeAlert(Alert alert) {
        AlertRecord record = new AlertRecord();
        record.setAlertId(alert.alertId());
        record.setMessageId(alert.messageId());
        record.setUserId(alert.userId());
        record.setAlertType(alert.alertType());
        record.setSeverity(alert.severity());
        record.setDescription(alert.description());
        record.setTimestamp(alert.timestamp());
        record.setProcessed(false);
        
        alertRecordRepository.save(record);
        log.info("é¢„è­¦å·²å­˜å‚¨: {}", record);
    }
}
```

## ğŸ”§ å¸¸ç”¨è°ƒè¯•æŠ€å·§

### 1. æŸ¥çœ‹Kafkaä¸­çš„æ•°æ®
```bash
# è¿›å…¥Kafkaå®¹å™¨
docker exec -it kafka bash

# æŸ¥çœ‹ä¸»é¢˜åˆ—è¡¨
kafka-topics.sh --list --bootstrap-server localhost:9092

# æŸ¥çœ‹ä¸»é¢˜å†…å®¹
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic social-messages --from-beginning
```

### 2. æ—¥å¿—æŸ¥çœ‹
```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/collector-service.log
tail -f logs/stream-analyzer.log
tail -f logs/alert-service.log
```

### 3. æ€§èƒ½ç›‘æ§
```java
// æ·»åŠ æ€§èƒ½ç›‘æ§
@Component
public class PerformanceMonitor {
    
    private final MeterRegistry meterRegistry;
    
    public void recordProcessingTime(String operation, long timeMs) {
        meterRegistry.timer("operation.time", "operation", operation)
                    .record(timeMs, TimeUnit.MILLISECONDS);
    }
    
    public void recordMessageCount(String topic, int count) {
        meterRegistry.counter("messages.processed", "topic", topic)
                    .increment(count);
    }
}
```

## ğŸš¨ å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜1ï¼šKafkaè¿æ¥å¤±è´¥
```
Error: Connection to node -1 could not be established.
```
**è§£å†³ï¼š**
1. æ£€æŸ¥Kafkaæ˜¯å¦å¯åŠ¨ï¼š`docker ps`
2. æ£€æŸ¥ç«¯å£æ˜¯å¦æ­£ç¡®ï¼š9092
3. æ£€æŸ¥ç½‘ç»œé…ç½®ï¼šbootstrap-servers

### é—®é¢˜2ï¼šåºåˆ—åŒ–é”™è¯¯
```
Error: Failed to deserialize message
```
**è§£å†³ï¼š**
1. æ£€æŸ¥ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…çš„åºåˆ—åŒ–é…ç½®æ˜¯å¦ä¸€è‡´
2. æ£€æŸ¥DTOç±»æ˜¯å¦æœ‰é»˜è®¤æ„é€ å‡½æ•°
3. æ£€æŸ¥JSONæ ¼å¼æ˜¯å¦æ­£ç¡®

### é—®é¢˜3ï¼šå†…å­˜æº¢å‡º
```
Error: OutOfMemoryError
```
**è§£å†³ï¼š**
1. å‡å°‘æ‰¹å¤„ç†å¤§å°
2. å¢åŠ JVMå†…å­˜ï¼š`-Xmx2g`
3. æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹å¤„ç†ä¼˜åŒ–
```java
// è°ƒæ•´æ‰¹å¤„ç†å‚æ•°
config.put(ProducerConfig.BATCH_SIZE_CONFIG, 32768);  // 32KB
config.put(ProducerConfig.LINGER_MS_CONFIG, 100);     // 100msç­‰å¾…
```

### 2. å¹¶è¡Œå¤„ç†
```java
// å¢åŠ å¹¶è¡Œåº¦
props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 4);
props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, "at_least_once");
```

### 3. ç¼“å­˜ä¼˜åŒ–
```java
// é…ç½®æœ¬åœ°ç¼“å­˜
props.put(StreamsConfig.STATE_DIR_CONFIG, "/tmp/kafka-streams");
props.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 10 * 1024 * 1024); // 10MB
```

## ğŸ¯ ä¸‹ä¸€æ­¥å­¦ä¹ è·¯çº¿

### é˜¶æ®µ1ï¼šå·©å›ºåŸºç¡€ï¼ˆ1-2å‘¨ï¼‰
- [ ] å®Œæ•´è·‘é€šç°æœ‰ä»£ç 
- [ ] ç†è§£æ¯ä¸ªé…ç½®çš„ä½œç”¨
- [ ] å­¦ä¼šæŸ¥çœ‹å’Œè§£è¯»æ—¥å¿—
- [ ] æŒæ¡åŸºæœ¬çš„è°ƒè¯•æŠ€å·§

### é˜¶æ®µ2ï¼šåŠŸèƒ½å®Œå–„ï¼ˆ2-3å‘¨ï¼‰
- [ ] å®Œå–„Alert-Serviceçš„æ‰€æœ‰åŠŸèƒ½
- [ ] æ·»åŠ æ•°æ®åº“æŒä¹…åŒ–
- [ ] å®ç°Web APIæ¥å£
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•

### é˜¶æ®µ3ï¼šè¿›é˜¶ä¼˜åŒ–ï¼ˆ3-4å‘¨ï¼‰
- [ ] é›†æˆçœŸå®çš„AIæœåŠ¡
- [ ] æ·»åŠ ç›‘æ§å’Œå‘Šè­¦
- [ ] æ€§èƒ½è°ƒä¼˜
- [ ] éƒ¨ç½²åˆ°æœåŠ¡å™¨

### é˜¶æ®µ4ï¼šé«˜çº§ç‰¹æ€§ï¼ˆæŒç»­ï¼‰
- [ ] å®ç°V1.5å†å²åˆ†æåŠŸèƒ½
- [ ] å­¦ä¹ Kafka Streamsçš„é«˜çº§ç‰¹æ€§
- [ ] å®ç°V2.0å®æ—¶äº¤äº’åŠŸèƒ½
- [ ] å¾®æœåŠ¡æ¶æ„ä¼˜åŒ–

## ğŸ“š æ¨èå­¦ä¹ èµ„æº

### åŸºç¡€æ•™ç¨‹
- [Kafkaå®˜æ–¹æ–‡æ¡£](https://kafka.apache.org/documentation/)
- [Spring Kafkaæ–‡æ¡£](https://spring.io/projects/spring-kafka)
- [Kafka Streamsæ–‡æ¡£](https://kafka.apache.org/documentation/streams/)

### è§†é¢‘æ•™ç¨‹
- Bç«™ï¼šKafkaåŸºç¡€æ•™ç¨‹
- æ…•è¯¾ç½‘ï¼šSpring Bootæ•´åˆKafka
- æå®¢æ—¶é—´ï¼šKafkaæ ¸å¿ƒæŠ€æœ¯ä¸å®æˆ˜

### å®è·µé¡¹ç›®
- [Kafka Streamsç¤ºä¾‹é¡¹ç›®](https://github.com/confluentinc/kafka-streams-examples)
- [Spring Kafkaç¤ºä¾‹](https://github.com/spring-projects/spring-kafka/tree/main/samples)

## ğŸ’¡ å¼€å‘å¿ƒå¾—æ€»ç»“

### âœ… å¥½çš„å®è·µ
1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ï¼Œä¾¿äºç»´æŠ¤å’Œæµ‹è¯•
2. **é…ç½®åˆ†ç¦»**ï¼šå°†é…ç½®é›†ä¸­ç®¡ç†ï¼Œä¾¿äºè°ƒæ•´
3. **å¼‚å¸¸å¤„ç†**ï¼šå®Œå–„çš„é™çº§æœºåˆ¶ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
4. **æ—¥å¿—è®°å½•**ï¼šè¯¦ç»†çš„æ—¥å¿—ä¾¿äºé—®é¢˜æ’æŸ¥

### âŒ é¿å…çš„é™·é˜±
1. **ä¸è¦ç¡¬ç¼–ç **ï¼šæ‰€æœ‰å‚æ•°éƒ½åº”è¯¥å¯é…ç½®
2. **ä¸è¦å¿½ç•¥å¼‚å¸¸**ï¼šæ¯ä¸ªå¼‚å¸¸éƒ½åº”è¯¥å¦¥å–„å¤„ç†
3. **ä¸è¦è¿‡åº¦ä¼˜åŒ–**ï¼šå…ˆè®©ç³»ç»Ÿè·‘èµ·æ¥ï¼Œå†è€ƒè™‘ä¼˜åŒ–
4. **ä¸è¦å¿½è§†ç›‘æ§**ï¼šæ²¡æœ‰ç›‘æ§çš„ç³»ç»Ÿå°±åƒç›²äººèµ°è·¯

### ğŸ¯ å…³é”®æˆåŠŸå› ç´ 
1. **ç†è§£æ•°æ®æµ**ï¼šæ¸…æ¥šæ•°æ®ä»å“ªé‡Œæ¥ï¼Œç»è¿‡ä»€ä¹ˆå¤„ç†ï¼Œåˆ°å“ªé‡Œå»
2. **æŒæ¡å¼‚æ­¥æ€ç»´**ï¼šæµå¤„ç†æ˜¯å¼‚æ­¥çš„ï¼Œè¦æœ‰å¼‚æ­¥ç¼–ç¨‹çš„æ€ç»´
3. **é‡è§†æ€§èƒ½**ï¼šæµå¤„ç†å¯¹æ€§èƒ½è¦æ±‚é«˜ï¼Œè¦å…³æ³¨å»¶è¿Ÿå’Œååé‡
4. **æŒç»­å­¦ä¹ **ï¼šæŠ€æœ¯æ›´æ–°å¾ˆå¿«ï¼Œè¦ä¿æŒå­¦ä¹ çš„ä¹ æƒ¯

---

**è®°ä½ï¼šæµå¤„ç†å°±åƒæ­ç§¯æœ¨ï¼Œå…ˆæŠŠåŸºç¡€çš„æ­å¥½ï¼Œå†æ…¢æ…¢æ·»åŠ é«˜çº§åŠŸèƒ½ã€‚ä¸è¦ç€æ€¥ï¼Œä¸€æ­¥ä¸€ä¸ªè„šå°ï¼** ğŸš€