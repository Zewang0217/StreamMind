# StreamMind v2.0 学习实践指南：从P3到1.0闭环


## **一、战略确认：为什么转向舆情监控？**

### **核心矛盾解决**
你发现的冲突完全正确：**流处理技术栈需要"真·实时+高并发"才能发挥价值**。舆情场景完美匹配：
- **真实压力**：热点事件评论峰值可达**数千条/秒**，你的窗口聚合、状态存储、背压控制都有用武之地
- **真实价值**：品牌方愿意为"5分钟内发现危机"付费，你的预警逻辑从"玩具"变"工具"
- **真实分布**：20-50个话题并行处理，分区策略、线程调优、状态管理全是硬技能

**转型不等于放弃**：P3的`groupByKey().windowBy().aggregate()`代码**几乎不用改**，只需换数据源和消息结构。你之前的投入全部有效。

---

## **二、微服务架构搭建（亲手做，AI答疑）**

### **终极目标**
三个独立服务，通过Kafka Topic松耦合：
```
collector-service  →  social-messages  →  stream-analyzer  →  alert-events  →  alert-service
                                                          ↘  analyzed-stream  ↗
```

**本周目标**：让这三个服务在本地跑通，浏览器能看到**实时跳动的图表**。

---

### **S1: collector-service（数据采集服务）**

**功能目标**：  
假装自己是"微博+知乎+抖音"的入口，**持续不断地**往Kafka灌数据。先不用管RSSHub，用**CSV文件模拟**制造压力。

**你需要亲手做的事**：

1. **创建独立Spring Boot项目**
   - 新建Maven模块，artifactId=`collector-service`
   - 依赖：`spring-boot-starter-web`, `spring-kafka`, `lombok`
   - **关键配置**：`spring.main.web-application-type=none`（纯后台任务，不启动Tomcat）

2. **定义消息结构`SocialMessage`**
   - 字段：messageId, source(weibo/zhihu), topic, userId, timestamp, content, interactionCount
   - **学习要点**：`messageId`必须全局唯一，思考如何保证？
     + UUID + timestamp 
   - **实践技巧**：用`record`类+`@JsonFormat`注解处理时间戳

3. **准备CSV数据集**
   - 网上找"微博舆情数据集"或知乎"如何看待XX"问题下的回答，爬1000条存为CSV
   - 格式：`userId,content,interactionCount,topic`
   - **学习要点**：数据脱敏，去掉真实用户名

4. **实现`SimulationCollector`类**
   - 用`@Scheduled(fixedDelay = 10)`每10ms触发一次
   - 每次从CSV读10行，发送Kafka
   - **核心挑战**：控制发送速度，太快会压垮AI，太慢看不到效果
   - **调优乐趣**：调整`fixedDelay`和每批条数，观察Kafka Lag变化

5. **Kafka Producer配置优化**
   - 配置`batch-size`, `linger-ms`, `compression-type`
   - **学习要点**：理解"批次"和"压缩"如何提升吞吐量

**验证成果**：  
- 启动服务后，在Kafka Console Consumer能看到**持续不断**的消息
- 执行`kafka-consumer-groups.sh --describe`看到Lag在增长（证明生产速度>消费速度）

**AI能帮你**：  
- 解释`ProducerConfig`每个参数的作用
- 帮你写CSV解析的样板代码
- 提示`messageId`生成的最佳实践

---

### **S2: stream-analyzer（流处理核心服务）**

**功能目标**：**纯后台**的Kafka Streams应用，从`social-messages`读，写`analyzed-stream`和`alert-events`。这是整个系统的大脑。

**你需要亲手做的事**：

1. **创建独立项目**
   - 依赖：`kafka-streams`, `google-cloud-vertexai`（Gemini SDK）, `resilience4j`（限流）
   - **关键配置**：`spring.main.web-application-type=none`

2. **改造P3拓扑结构**
   - 保留`groupByKey().windowBy().aggregate()`骨架
   - **调整点**：窗口从60秒改为**5分钟**，跳跃从30秒改为**2分钟**（更真实）
   - **新增点**：在`aggregate()`后加`filter()`，条件改为`messageCount > 1000 && negativeRatio > 0.7`

3. **实现`BatchAiAnalysisProcessor`**
   - 这是**最难也最 rewarding**的部分
   - 用`ArrayList`缓冲消息，达到50条调用一次Gemini
   - **学习要点**：理解`ProcessorContext.schedule()`如何避免最后一批消息卡住
   - **实践技巧**：在`process()`里用`log.debug()`打印每批大小，监控内存

4. **Gemini Prompt工程**
   - 要求AI返回**严格JSON数组**，每条包含sentimentScore/-1~1, toxicityScore/0~1, keywords
   - **学习要点**：AI输出不稳定，必须加`responseFormat: "json"`参数
   - **实践技巧**：先调通单条调用，再改为批量

5. **降级策略**
   - 当Gemini限流或失败时，用**关键词匹配**兜底（正面词+0.5，负面词-0.5）
   - **学习要点**：`try-catch`住AI调用，返回`fallbackAnalysis()`
   - **进阶思考**：降级逻辑如何不影响聚合结果？

6. **状态存储观察**
   - 配置`state.dir=/tmp/kafka-streams`
   - **学习要点**：在`/tmp`下查看RocksDB文件，理解"状态"到底存在哪
   - **验证方法**：重启服务，观察状态是否能恢复

**验证成果**：  
- 启动后，`analyzed-stream` Topic有消息输出
- 手动往`social-messages`发一条负面消息，2分钟后`alert-events`出现预警
- 用Kafka Tool查看`topic-stats-store`的changelog Topic

**AI能帮你**：  
- 解释`TimeWindows.ofSizeWithNoGrace()`的"无宽限"含义
- 帮你调试BatchProcessor的定时刷新逻辑
- 提供关键词词库作为降级方案

---

### **S3: alert-service（预警消费与Web推送）**

**功能目标**：**轻量级Web服务**，消费预警，存数据库，推送到浏览器。这是你唯一能"看见"成果的服务。

**你需要亲手做的事**：

1. **创建标准Spring Boot Web项目**
   - 依赖：`spring-boot-starter-web`, `spring-boot-starter-websocket`, `spring-data-jpa`, `postgresql`
   - 端口：`server.port=8080`

2. **PostgreSQL表设计**
   - 表名`alerts`，字段：topic, window_end, negative_ratio, message, severity, created_at
   - **学习要点**：`window_end`加索引，用于查询最近预警
   - **实践技巧**：用`ddl-auto=update`自动建表，但生产环境必须手写SQL

3. **实现AlertRepository**
   - 继承`JpaRepository<Alert, Long>`
   - **自定义查询**：`findBySeverityGreaterThanAndCreatedAtAfter()`查严重预警
   - **学习要点**：理解JPA方法名派生查询规则

4. **WebSocket配置**
   - 启用STOMP，端点`/ws-stream`
   - **学习要点**：`SockJS`的作用（兼容不支持WebSocket的浏览器）
   - **实践技巧**：用Postman测试WebSocket连接

5. **Kafka Consumer实现**
   - 用`@KafkaListener`消费`alert-events`，批量接收（`max.poll.records=50`）
   - **核心逻辑**：去重→存DB→WebSocket推送→打印日志
   - **学习要点**：消费组`group.id`如何影响负载均衡？

6. **Thymeleaf + Chart.js页面**
   - 引入Chart.js CDN，canvas画折线图
   - **学习要点**：Chart.js的`update('none')`无动画更新性能更好
   - **实践技巧**：前端只保留最近20个数据点，防止内存泄漏

7. **压测与调优**
   - 用`kafka-producer-perf-test`往`social-messages`灌10万条数据
   - 观察浏览器图表是否卡顿，WebSocket推送延迟
   - **学习要点**：浏览器端消息队列堆积如何处理？

**验证成果**：  
- 打开`http://localhost:8080`，看到空图表
- 触发预警后，浏览器弹出红色横幅，图表出现新数据点
- PostgreSQL里`SELECT * FROM alerts`有数据

**AI能帮你**：  
- 解释JPA的`@Entity`生命周期
- 帮你调通WebSocket的跨域问题
- 提供Chart.js的配置模板

---

## **三、1.0版本闭环检查清单**

### **环境准备**
- [ ] Docker Compose启动ZooKeeper+Kafka+PostgreSQL
- [ ] 手动创建所需Topic（AI可教你命令）
- [ ] 配置`application.yml`中的连接信息

### **服务验证顺序**
1. **启动S1**：看到CSV数据持续写入`social-messages`，Lag增长
2. **启动S2**：`stream-analyzer`日志打印"Processed batch of 50 messages"，RocksDB目录出现文件
3. **启动S3**：浏览器打开`localhost:8080`，页面加载成功
4. **触发预警**：手动在CSV里准备1000条负面数据，观察2分钟内是否弹窗

### **核心指标观察**
- **吞吐量**：`kafka-consumer-groups.sh`查看每秒处理条数
- **延迟**：从消息进`social-messages`到出`alert-events`的时间差（目标<30秒）
- **AI成本**：Gemini Dashboard查看调用次数，计算单条成本
- **系统资源**：`jconsole`连接S2，观察堆内存和RocksDB缓存

---

## **四、1.5到2.0演进路径（学习路线图）**

### **1.5版本：高并发验证（下周）**
**目标**：证明系统能扛住**1万QPS**，理解瓶颈所在

**你需要做的事**：
1. **爬取真实数据**：用Python+RSSHub爬10万条微博评论，存CSV
2. **性能监控**：引入`Micrometer` + `Prometheus`，监控Kafka Lag、处理延迟
3. **状态查询API**：在S2添加REST端点，查询某话题的当前窗口统计
4. **压测工具**：用`k6`写脚本，模拟100个并发Producer
5. **调优实验**：调整`num.stream.threads`和`cache.max.bytes`，观察吞吐量变化

**学习产出**：一份压测报告，写明QPS、延迟、瓶颈（网络/AI/CPU）

### **2.0版本：微服务深化（下月）**
**目标**：服务可独立部署、独立扩展

**你需要做的事**：
1. **Docker化**：为每个服务写Dockerfile，多阶段构建减小镜像
2. **配置中心**：部署Spring Cloud Config Server，配置文件放Git
3. **服务发现**：部署Nacos，三个服务注册上去
4. **API网关**：Spring Cloud Gateway路由到不同服务
5. **前端升级**：用Vue3替代Thymeleaf，但保留WebSocket逻辑

**学习产出**：一条`docker-compose up -d`命令拉起整个系统，Nacos Dashboard看到三个健康服务

---

## **五、AI协作模式：你提问，AI解答**

你现在不需要AI写代码，而是需要AI当 **即时导师** 。以下是**高效提问模板**：

### **提问模板1：概念理解**
> "我调大了`linger.ms`，吞吐量提升了但延迟也增加了。这是为什么？Kafka的Producer批次机制到底怎么工作的？"

### **提问模板2：异常排查**
> "我的`stream-analyzer`启动了，但Lag一直在涨，日志没报错。可能是什么原因？我应该如何一步步排查？"

### **提问模板3：设计权衡**
> "我用ArrayList缓冲消息，但担心OOM。换成LinkedList会不会更好？或者我应该限制缓冲区大小？"

### **提问模板4：调优方向**
> "我压测到5000 QPS时，Gemini API开始限流。除了降低调用频率，还有哪些优雅的降级方案？"

### **提问模板5：代码审查**
> "这是我写的`BatchAiAnalysisProcessor.flush()`方法，帮我看看有没有资源泄漏或线程安全问题？"

**AI的回答策略**：  
- 先讲**原理**，再讲**实践**
- 提供**最小可运行示例**验证你的理解
- 指出**常见陷阱**和**最佳实践**
- 最后问你："你希望我针对哪部分展开讲？"

---

## **六、避坑指南：学习者的常见陷阱**

1. ** 服务没解耦 **：S3直接调用S2的API → 必须** 只通过Kafka通信 **，这是事件驱动的核心
2. ** AI调用阻塞 **：在`process()`里同步调Gemini → 必须用批量+异步，否则吞吐量起不来
3. ** 前端过度优化 **：用React写复杂Dashboard → ** 先让Chart.js跑起来 **，用户只有你自己
4. ** 监控太多指标 **：Grafana配20个图表 → ** 先盯准Kafka Lag和端到端延迟 **
5. ** 配置文件乱放 **：每个服务一个`application.yml` → 1.5版本后必须集中管理
6. ** 忽视资源清理 **：State Store文件不断膨胀 → 理解Kafka Streams的** 日志压缩**和`retention.ms`

---

## **七、本周最小行动计划（AI监督你完成）**

**Day 1（今晚）**：  
- [ ] 创建三个Maven模块，在根`pom.xml`中聚合
- [ ] 在`common`模块定义`SocialMessage.java`
- [ ] 准备100条测试CSV数据

**Day 2-3**：  
- [ ] S1能读取CSV并发送到Kafka，日志确认发送成功
- [ ] S2的拓扑结构搭建完成，能消费消息并打印到控制台

**Day 4-5**：  
- [ ] S2集成Gemini，单条调用调通
- [ ] 改造为批量50条调用，观察成本

**Day 6-7**：  
- [ ] S3的WebSocket推送到浏览器
- [ ] 在`dashboard.html`里用Chart.js画出第一条线

**AI在周末会问你**："看到图表动了吗？Lag多少？预警弹窗长啥样？" —— 这是你交付的1.0成果。

---

## **八、最后的话**

你已经完成了最艰难的P3，现在只是换个场景**重新组装**。记住三件事：

1. **别求完美**：1.0版本只要能跑，预警能弹窗，就是成功
2. **多问为什么**：每调一个参数，先问AI"这会影响什么"
3. **享受调优**：当你把Lag从10000降到100时，那种成就感是买不来的

加油，等你1.0的好消息！